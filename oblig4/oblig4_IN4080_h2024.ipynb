{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN4080: obligatory assignment 4\n",
    " \n",
    "The final mandatory assignment for IN4080 consists of two parts. The first is about the development of dialogue systems, and the second about machine translation.\n",
    "You are required to get at least 12/20 points to pass. \n",
    "\n",
    "- We assume that you have read and are familiar with IFI’s requirements and guidelines for mandatory assignments, see [here](https://www.uio.no/english/studies/examinations/compulsory-activities/mn-ifi-mandatory.html) and [here](https://www.uio.no/english/studies/examinations/compulsory-activities/mn-ifi-guidelines.html).\n",
    "- This is an individual assignment. You should not deliver joint submissions. \n",
    "- You may redeliver in Devilry before the deadline (__Sunday, November 3 at 23:59__).\n",
    "- Only the last delivery will be read! If you deliver more than one file, put them into a zip-archive. You don't have to include in your delivery the data files already provided for this assignment. \n",
    "- Name your submission _your\\_username\\_in4080\\_mandatory\\_4_\n",
    "\n",
    "Part 1 should be done on your local computer, as it relies on a speech interface that will not work on remote machines. For Part 2, using _Fox_ is preferable, at least for the fine-tuning task.\n",
    "\n",
    "You should deliver a completed version of this Jupyter notebook, containing both your code and explanations about the steps you followed. We want to stress that simply submitting code is __not__ by itself sufficient to complete the assignment - we expect the notebook to also contain explanations of what you have implemented, along with motivations for the choices you made along the way. Preferably use whole sentences, and mathematical formulas if necessary. Explaining in your own words (using concepts we have covered through in the lectures) what you have implemented and reflecting on your solution is an important part of the learning process - take it seriously!\n",
    "\n",
    "Regarding the use of LLMs (ChatGPT or similar): you are allowed to use them as 'sparring partner', for instance to clarify something you have not understood. However, you are __not__ allowed to use them to generate solutions (either in part or in full) to the assignment tasks. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 : Dialogue systems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective in this part is to build a spoken conversational interface for a (simulated) elevator. \n",
    "\n",
    "### Basic setup\n",
    "\n",
    "First, let's make sure that we have all the necessary Python modules:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "130803.24s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (8.1.1)\n",
      "Collecting pyaudio\n",
      "  Using cached PyAudio-0.2.14.tar.gz (47 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting openai-whisper\n",
      "  Using cached openai-whisper-20240930.tar.gz (800 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting pyttsx3\n",
      "  Using cached pyttsx3-2.98-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting setfit\n",
      "  Using cached setfit-1.1.0-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: spacy in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (3.7.2)\n",
      "Requirement already satisfied: jellyfish in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (1.1.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from ipywidgets) (0.2.0)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from ipywidgets) (8.19.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from ipywidgets) (5.14.0)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.9 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from ipywidgets) (4.0.9)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.9 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from ipywidgets) (3.0.9)\n",
      "Collecting numba (from openai-whisper)\n",
      "  Downloading numba-0.60.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: numpy in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from openai-whisper) (1.23.4)\n",
      "Requirement already satisfied: torch in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from openai-whisper) (1.12.1)\n",
      "Requirement already satisfied: tqdm in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from openai-whisper) (4.66.4)\n",
      "Requirement already satisfied: more-itertools in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from openai-whisper) (9.0.0)\n",
      "Requirement already satisfied: tiktoken in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from openai-whisper) (0.7.0)\n",
      "Collecting pyobjc>=2.4 (from pyttsx3)\n",
      "  Using cached pyobjc-10.3.1-py3-none-any.whl.metadata (26 kB)\n",
      "Collecting datasets>=2.15.0 (from setfit)\n",
      "  Using cached datasets-3.0.2-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting sentence-transformers>=3 (from sentence-transformers[train]>=3->setfit)\n",
      "  Using cached sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers>=4.41.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from setfit) (4.45.1)\n",
      "Collecting evaluate>=0.3.0 (from setfit)\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from setfit) (0.25.1)\n",
      "Requirement already satisfied: scikit-learn in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from setfit) (1.1.3)\n",
      "Requirement already satisfied: packaging in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from setfit) (24.1)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (6.2.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (2.28.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (1.10.4)\n",
      "Requirement already satisfied: jinja2 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (65.5.0)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy) (3.3.0)\n",
      "Requirement already satisfied: filelock in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from datasets>=2.15.0->setfit) (3.8.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from datasets>=2.15.0->setfit) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from datasets>=2.15.0->setfit) (0.3.7)\n",
      "Requirement already satisfied: pandas in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from datasets>=2.15.0->setfit) (1.5.1)\n",
      "Collecting requests<3.0.0,>=2.13.0 (from spacy)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: xxhash in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from datasets>=2.15.0->setfit) (3.4.1)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from datasets>=2.15.0->setfit) (0.70.15)\n",
      "Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets>=2.15.0->setfit) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from datasets>=2.15.0->setfit) (3.8.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from datasets>=2.15.0->setfit) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from huggingface-hub>=0.23.0->setfit) (4.12.2)\n",
      "Requirement already satisfied: decorator in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.13.0)\n",
      "Requirement already satisfied: stack-data in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: exceptiongroup in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.2.2)\n",
      "Requirement already satisfied: pexpect>4.3 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Collecting pyobjc-core==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_core-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.5 kB)\n",
      "Collecting pyobjc-framework-AddressBook==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_AddressBook-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-AppleScriptKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_AppleScriptKit-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-ApplicationServices==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_ApplicationServices-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.6 kB)\n",
      "Collecting pyobjc-framework-Automator==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Automator-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.5 kB)\n",
      "Collecting pyobjc-framework-CFNetwork==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CFNetwork-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.5 kB)\n",
      "Collecting pyobjc-framework-Cocoa==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_Cocoa-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-CoreAudio==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_CoreAudio-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-CoreAudioKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CoreAudioKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-CoreData==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CoreData-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-CoreMIDI==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CoreMIDI-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-CoreServices==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CoreServices-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-CoreText==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_CoreText-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.5 kB)\n",
      "Collecting pyobjc-framework-DiscRecording==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_DiscRecording-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-DiscRecordingUI==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_DiscRecordingUI-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-DiskArbitration==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_DiskArbitration-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-DVDPlayback==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_DVDPlayback-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-ExceptionHandling==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ExceptionHandling-10.3.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pyobjc-framework-InstallerPlugins==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_InstallerPlugins-10.3.1-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyobjc-framework-IOBluetooth==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_IOBluetooth-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-IOBluetoothUI==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_IOBluetoothUI-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-LatentSemanticMapping==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_LatentSemanticMapping-10.3.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pyobjc-framework-LaunchServices==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_LaunchServices-10.3.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pyobjc-framework-OSAKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_OSAKit-10.3.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-PreferencePanes==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_PreferencePanes-10.3.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-Quartz==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_Quartz-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (3.3 kB)\n",
      "Collecting pyobjc-framework-ScreenSaver==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ScreenSaver-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-Security==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_Security-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-SecurityFoundation==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_SecurityFoundation-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-SecurityInterface==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_SecurityInterface-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-SearchKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_SearchKit-10.3.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pyobjc-framework-SyncServices==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_SyncServices-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.6 kB)\n",
      "Collecting pyobjc-framework-SystemConfiguration==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_SystemConfiguration-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-WebKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_WebKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-AppleScriptObjC==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_AppleScriptObjC-10.3.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-CoreLocation==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CoreLocation-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-CoreWLAN==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CoreWLAN-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-ImageCaptureCore==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ImageCaptureCore-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-IOSurface==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_IOSurface-10.3.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-NetFS==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_NetFS-10.3.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-OpenDirectory==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_OpenDirectory-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-ServiceManagement==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ServiceManagement-10.3.1-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyobjc-framework-iTunesLibrary==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_iTunesLibrary-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-AVFoundation==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_AVFoundation-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-CoreMedia==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_CoreMedia-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-CoreMediaIO==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CoreMediaIO-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-StoreKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_StoreKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-SceneKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_SceneKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-libdispatch==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_libdispatch-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-libxpc==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_libxpc-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-AudioVideoBridging==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_AudioVideoBridging-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-Accounts==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Accounts-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-EventKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_EventKit-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-GameCenter==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_GameCenter-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-Social==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Social-10.3.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pyobjc-framework-GameKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_GameKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-VideoToolbox==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_VideoToolbox-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-AVKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_AVKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-GameController==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_GameController-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-MapKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_MapKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-MediaAccessibility==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_MediaAccessibility-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-MediaLibrary==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_MediaLibrary-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-MediaToolbox==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_MediaToolbox-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-SpriteKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_SpriteKit-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-CloudKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CloudKit-10.3.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-CoreBluetooth==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CoreBluetooth-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-CryptoTokenKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CryptoTokenKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-FinderSync==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_FinderSync-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-LocalAuthentication==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_LocalAuthentication-10.3.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-MultipeerConnectivity==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_MultipeerConnectivity-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-NotificationCenter==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_NotificationCenter-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-Contacts==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Contacts-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-ContactsUI==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ContactsUI-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-Metal==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Metal-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-MetalKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_MetalKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-ModelIO==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ModelIO-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-NetworkExtension==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_NetworkExtension-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-Photos==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Photos-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-PhotosUI==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_PhotosUI-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-GameplayKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_GameplayKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-Intents==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Intents-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-MediaPlayer==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_MediaPlayer-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-SafariServices==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_SafariServices-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-ColorSync==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ColorSync-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-CoreML==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CoreML-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-CoreSpotlight==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CoreSpotlight-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-ExternalAccessory==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ExternalAccessory-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-MetalPerformanceShaders==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_MetalPerformanceShaders-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-Vision==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Vision-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-AdSupport==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_AdSupport-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-BusinessChat==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_BusinessChat-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-NaturalLanguage==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_NaturalLanguage-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-Network==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Network-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-UserNotifications==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_UserNotifications-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-VideoSubscriberAccount==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_VideoSubscriberAccount-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-AuthenticationServices==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_AuthenticationServices-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-AutomaticAssessmentConfiguration==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_AutomaticAssessmentConfiguration-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-CoreHaptics==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CoreHaptics-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-CoreMotion==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_CoreMotion-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-DeviceCheck==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_DeviceCheck-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-ExecutionPolicy==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ExecutionPolicy-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-FileProvider==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_FileProvider-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-FileProviderUI==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_FileProviderUI-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-LinkPresentation==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_LinkPresentation-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-OSLog==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_OSLog-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-PencilKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_PencilKit-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-PushKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_PushKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-QuickLookThumbnailing==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_QuickLookThumbnailing-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-Speech==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Speech-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-SoundAnalysis==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_SoundAnalysis-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-SystemExtensions==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_SystemExtensions-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-Accessibility==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Accessibility-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-AdServices==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_AdServices-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-AppTrackingTransparency==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_AppTrackingTransparency-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-CallKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CallKit-10.3.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-ClassKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ClassKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-KernelManagement==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_KernelManagement-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-MetalPerformanceShadersGraph==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_MetalPerformanceShadersGraph-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-MLCompute==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_MLCompute-10.3.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-PassKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_PassKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-ReplayKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ReplayKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-ScreenTime==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ScreenTime-10.3.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-UniformTypeIdentifiers==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_UniformTypeIdentifiers-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-UserNotificationsUI==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_UserNotificationsUI-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-Virtualization==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Virtualization-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-DataDetection==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_DataDetection-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-IntentsUI==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_IntentsUI-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-LocalAuthenticationEmbeddedUI==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_LocalAuthenticationEmbeddedUI-10.3.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-MailKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_MailKit-10.3.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-MetricKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_MetricKit-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-PHASE==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_PHASE-10.3.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-ShazamKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_ShazamKit-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-ScreenCaptureKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Downloading pyobjc_framework_ScreenCaptureKit-10.3.1-cp310-cp310-macosx_10_9_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-AVRouting==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_AVRouting-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-BackgroundAssets==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_BackgroundAssets-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-ExtensionKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ExtensionKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-HealthKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_HealthKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-MetalFX==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_MetalFX-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-SafetyKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_SafetyKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-SharedWithYouCore==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_SharedWithYouCore-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-SharedWithYou==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_SharedWithYou-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-ThreadNetwork==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ThreadNetwork-10.3.1-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting pyobjc-framework-Cinematic==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Cinematic-10.3.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-SensitiveContentAnalysis==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_SensitiveContentAnalysis-10.3.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-Symbols==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Symbols-10.3.1-py2.py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting pyobjc-framework-BrowserEngineKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_BrowserEngineKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-CalendarStore==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_CalendarStore-10.3.1-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting pyobjc-framework-Collaboration==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_Collaboration-10.3.1-py2.py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-DictionaryServices==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_DictionaryServices-10.3.1-py2.py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting pyobjc-framework-FSEvents==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_FSEvents-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-InputMethodKit==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_InputMethodKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.4 kB)\n",
      "Collecting pyobjc-framework-InstantMessage==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_InstantMessage-10.3.1-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting pyobjc-framework-ScriptingBridge==10.3.1 (from pyobjc>=2.4->pyttsx3)\n",
      "  Using cached pyobjc_framework_ScriptingBridge-10.3.1-cp36-abi3-macosx_11_0_universal2.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2022.9.24)\n",
      "Requirement already satisfied: scipy in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (1.9.3)\n",
      "Requirement already satisfied: Pillow in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from sentence-transformers>=3->sentence-transformers[train]>=3->setfit) (9.2.0)\n",
      "Requirement already satisfied: accelerate>=0.20.3 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from sentence-transformers[train]>=3->setfit) (0.33.0)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy) (0.1.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from transformers>=4.41.0->setfit) (2023.12.25)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from transformers>=4.41.0->setfit) (0.4.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from transformers>=4.41.0->setfit) (0.20.0)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from jinja2->spacy) (2.1.1)\n",
      "Collecting llvmlite<0.44,>=0.43.0dev0 (from numba->openai-whisper)\n",
      "  Downloading llvmlite-0.43.0-cp310-cp310-macosx_11_0_arm64.whl.metadata (4.8 kB)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from scikit-learn->setfit) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from scikit-learn->setfit) (3.1.0)\n",
      "Requirement already satisfied: psutil in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from accelerate>=0.20.3->sentence-transformers[train]>=3->setfit) (5.9.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from aiohttp->datasets>=2.15.0->setfit) (22.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from aiohttp->datasets>=2.15.0->setfit) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from aiohttp->datasets>=2.15.0->setfit) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from aiohttp->datasets>=2.15.0->setfit) (1.8.1)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from aiohttp->datasets>=2.15.0->setfit) (1.3.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from aiohttp->datasets>=2.15.0->setfit) (1.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from pandas->datasets>=2.15.0->setfit) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from pandas->datasets>=2.15.0->setfit) (2022.5)\n",
      "Requirement already satisfied: executing>=1.2.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.0.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (2.4.1)\n",
      "Requirement already satisfied: pure-eval in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from stack-data->ipython>=6.1.0->ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: six>=1.12.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from asttokens>=2.1.0->stack-data->ipython>=6.1.0->ipywidgets) (1.16.0)\n",
      "Using cached pyttsx3-2.98-py3-none-any.whl (34 kB)\n",
      "Using cached setfit-1.1.0-py3-none-any.whl (75 kB)\n",
      "Using cached datasets-3.0.2-py3-none-any.whl (472 kB)\n",
      "Using cached evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
      "Using cached pyobjc-10.3.1-py3-none-any.whl (4.0 kB)\n",
      "Downloading pyobjc_core-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (774 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m774.3/774.3 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyobjc_framework_Accessibility-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (10 kB)\n",
      "Using cached pyobjc_framework_Accounts-10.3.1-py2.py3-none-any.whl (4.7 kB)\n",
      "Using cached pyobjc_framework_AddressBook-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (13 kB)\n",
      "Using cached pyobjc_framework_AdServices-10.3.1-py2.py3-none-any.whl (3.1 kB)\n",
      "Using cached pyobjc_framework_AdSupport-10.3.1-py2.py3-none-any.whl (3.0 kB)\n",
      "Using cached pyobjc_framework_AppleScriptKit-10.3.1-py2.py3-none-any.whl (3.9 kB)\n",
      "Using cached pyobjc_framework_AppleScriptObjC-10.3.1-py2.py3-none-any.whl (4.0 kB)\n",
      "Downloading pyobjc_framework_ApplicationServices-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (31 kB)\n",
      "Using cached pyobjc_framework_AppTrackingTransparency-10.3.1-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading pyobjc_framework_AudioVideoBridging-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (11 kB)\n",
      "Using cached pyobjc_framework_AuthenticationServices-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (19 kB)\n",
      "Using cached pyobjc_framework_AutomaticAssessmentConfiguration-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (8.9 kB)\n",
      "Using cached pyobjc_framework_Automator-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (10 kB)\n",
      "Using cached pyobjc_framework_AVFoundation-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (67 kB)\n",
      "Using cached pyobjc_framework_AVKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (12 kB)\n",
      "Using cached pyobjc_framework_AVRouting-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (8.6 kB)\n",
      "Using cached pyobjc_framework_BackgroundAssets-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (10 kB)\n",
      "Using cached pyobjc_framework_BrowserEngineKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (10 kB)\n",
      "Using cached pyobjc_framework_BusinessChat-10.3.1-py2.py3-none-any.whl (3.1 kB)\n",
      "Using cached pyobjc_framework_CalendarStore-10.3.1-py2.py3-none-any.whl (4.9 kB)\n",
      "Using cached pyobjc_framework_CallKit-10.3.1-py2.py3-none-any.whl (4.9 kB)\n",
      "Using cached pyobjc_framework_CFNetwork-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (19 kB)\n",
      "Using cached pyobjc_framework_Cinematic-10.3.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Using cached pyobjc_framework_ClassKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (8.7 kB)\n",
      "Using cached pyobjc_framework_CloudKit-10.3.1-py2.py3-none-any.whl (10 kB)\n",
      "Downloading pyobjc_framework_Cocoa-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (396 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m396.2/396.2 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hUsing cached pyobjc_framework_Collaboration-10.3.1-py2.py3-none-any.whl (4.5 kB)\n",
      "Using cached pyobjc_framework_ColorSync-10.3.1-py2.py3-none-any.whl (5.6 kB)\n",
      "Using cached pyobjc_framework_Contacts-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (12 kB)\n",
      "Using cached pyobjc_framework_ContactsUI-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (8.3 kB)\n",
      "Downloading pyobjc_framework_CoreAudio-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (35 kB)\n",
      "Using cached pyobjc_framework_CoreAudioKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (7.5 kB)\n",
      "Using cached pyobjc_framework_CoreBluetooth-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (13 kB)\n",
      "Using cached pyobjc_framework_CoreData-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (17 kB)\n",
      "Using cached pyobjc_framework_CoreHaptics-10.3.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Using cached pyobjc_framework_CoreLocation-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (12 kB)\n",
      "Downloading pyobjc_framework_CoreMedia-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (29 kB)\n",
      "Using cached pyobjc_framework_CoreMediaIO-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (17 kB)\n",
      "Using cached pyobjc_framework_CoreMIDI-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (17 kB)\n",
      "Using cached pyobjc_framework_CoreML-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (11 kB)\n",
      "Downloading pyobjc_framework_CoreMotion-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (9.8 kB)\n",
      "Using cached pyobjc_framework_CoreServices-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (29 kB)\n",
      "Using cached pyobjc_framework_CoreSpotlight-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (10 kB)\n",
      "Downloading pyobjc_framework_CoreText-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (30 kB)\n",
      "Using cached pyobjc_framework_CoreWLAN-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (10 kB)\n",
      "Using cached pyobjc_framework_CryptoTokenKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (13 kB)\n",
      "Using cached pyobjc_framework_DataDetection-10.3.1-py2.py3-none-any.whl (3.1 kB)\n",
      "Using cached pyobjc_framework_DeviceCheck-10.3.1-py2.py3-none-any.whl (3.3 kB)\n",
      "Using cached pyobjc_framework_DictionaryServices-10.3.1-py2.py3-none-any.whl (3.5 kB)\n",
      "Using cached pyobjc_framework_DiscRecording-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (14 kB)\n",
      "Using cached pyobjc_framework_DiscRecordingUI-10.3.1-py2.py3-none-any.whl (4.3 kB)\n",
      "Using cached pyobjc_framework_DiskArbitration-10.3.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Using cached pyobjc_framework_DVDPlayback-10.3.1-py2.py3-none-any.whl (7.8 kB)\n",
      "Using cached pyobjc_framework_EventKit-10.3.1-py2.py3-none-any.whl (6.4 kB)\n",
      "Using cached pyobjc_framework_ExceptionHandling-10.3.1-py2.py3-none-any.whl (6.7 kB)\n",
      "Using cached pyobjc_framework_ExecutionPolicy-10.3.1-py2.py3-none-any.whl (3.3 kB)\n",
      "Using cached pyobjc_framework_ExtensionKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (8.3 kB)\n",
      "Using cached pyobjc_framework_ExternalAccessory-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (9.3 kB)\n",
      "Downloading pyobjc_framework_FileProvider-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (18 kB)\n",
      "Using cached pyobjc_framework_FileProviderUI-10.3.1-py2.py3-none-any.whl (3.3 kB)\n",
      "Using cached pyobjc_framework_FinderSync-10.3.1-py2.py3-none-any.whl (4.5 kB)\n",
      "Using cached pyobjc_framework_FSEvents-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (12 kB)\n",
      "Using cached pyobjc_framework_GameCenter-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (19 kB)\n",
      "Using cached pyobjc_framework_GameController-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (20 kB)\n",
      "Using cached pyobjc_framework_GameKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (22 kB)\n",
      "Using cached pyobjc_framework_GameplayKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (13 kB)\n",
      "Using cached pyobjc_framework_HealthKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (19 kB)\n",
      "Using cached pyobjc_framework_ImageCaptureCore-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (16 kB)\n",
      "Using cached pyobjc_framework_InputMethodKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (9.8 kB)\n",
      "Using cached pyobjc_framework_InstallerPlugins-10.3.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Using cached pyobjc_framework_InstantMessage-10.3.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Using cached pyobjc_framework_Intents-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (32 kB)\n",
      "Downloading pyobjc_framework_IntentsUI-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (9.6 kB)\n",
      "Using cached pyobjc_framework_IOBluetooth-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (41 kB)\n",
      "Using cached pyobjc_framework_IOBluetoothUI-10.3.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Using cached pyobjc_framework_IOSurface-10.3.1-py2.py3-none-any.whl (4.6 kB)\n",
      "Using cached pyobjc_framework_iTunesLibrary-10.3.1-py2.py3-none-any.whl (4.8 kB)\n",
      "Using cached pyobjc_framework_KernelManagement-10.3.1-py2.py3-none-any.whl (3.3 kB)\n",
      "Using cached pyobjc_framework_LatentSemanticMapping-10.3.1-py2.py3-none-any.whl (5.0 kB)\n",
      "Using cached pyobjc_framework_LaunchServices-10.3.1-py2.py3-none-any.whl (3.5 kB)\n",
      "Downloading pyobjc_framework_libdispatch-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (20 kB)\n",
      "Downloading pyobjc_framework_libxpc-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (19 kB)\n",
      "Using cached pyobjc_framework_LinkPresentation-10.3.1-py2.py3-none-any.whl (3.5 kB)\n",
      "Using cached pyobjc_framework_LocalAuthentication-10.3.1-py2.py3-none-any.whl (5.7 kB)\n",
      "Using cached pyobjc_framework_LocalAuthenticationEmbeddedUI-10.3.1-py2.py3-none-any.whl (3.6 kB)\n",
      "Using cached pyobjc_framework_MailKit-10.3.1-py2.py3-none-any.whl (4.5 kB)\n",
      "Using cached pyobjc_framework_MapKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (22 kB)\n",
      "Using cached pyobjc_framework_MediaAccessibility-10.3.1-py2.py3-none-any.whl (4.1 kB)\n",
      "Using cached pyobjc_framework_MediaLibrary-10.3.1-py2.py3-none-any.whl (4.0 kB)\n",
      "Using cached pyobjc_framework_MediaPlayer-10.3.1-py2.py3-none-any.whl (6.5 kB)\n",
      "Using cached pyobjc_framework_MediaToolbox-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (13 kB)\n",
      "Using cached pyobjc_framework_Metal-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (55 kB)\n",
      "Using cached pyobjc_framework_MetalFX-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (10 kB)\n",
      "Using cached pyobjc_framework_MetalKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (9.1 kB)\n",
      "Using cached pyobjc_framework_MetalPerformanceShaders-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (33 kB)\n",
      "Using cached pyobjc_framework_MetalPerformanceShadersGraph-10.3.1-py2.py3-none-any.whl (6.0 kB)\n",
      "Downloading pyobjc_framework_MetricKit-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (8.2 kB)\n",
      "Using cached pyobjc_framework_MLCompute-10.3.1-py2.py3-none-any.whl (6.4 kB)\n",
      "Using cached pyobjc_framework_ModelIO-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (21 kB)\n",
      "Using cached pyobjc_framework_MultipeerConnectivity-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (12 kB)\n",
      "Using cached pyobjc_framework_NaturalLanguage-10.3.1-py2.py3-none-any.whl (4.9 kB)\n",
      "Using cached pyobjc_framework_NetFS-10.3.1-py2.py3-none-any.whl (3.8 kB)\n",
      "Using cached pyobjc_framework_Network-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (14 kB)\n",
      "Using cached pyobjc_framework_NetworkExtension-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (14 kB)\n",
      "Using cached pyobjc_framework_NotificationCenter-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (10 kB)\n",
      "Using cached pyobjc_framework_OpenDirectory-10.3.1-py2.py3-none-any.whl (11 kB)\n",
      "Using cached pyobjc_framework_OSAKit-10.3.1-py2.py3-none-any.whl (3.8 kB)\n",
      "Using cached pyobjc_framework_OSLog-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (8.1 kB)\n",
      "Using cached pyobjc_framework_PassKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (13 kB)\n",
      "Using cached pyobjc_framework_PencilKit-10.3.1-py2.py3-none-any.whl (3.7 kB)\n",
      "Using cached pyobjc_framework_PHASE-10.3.1-py2.py3-none-any.whl (6.2 kB)\n",
      "Using cached pyobjc_framework_Photos-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (12 kB)\n",
      "Using cached pyobjc_framework_PhotosUI-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (12 kB)\n",
      "Using cached pyobjc_framework_PreferencePanes-10.3.1-py2.py3-none-any.whl (4.4 kB)\n",
      "Using cached pyobjc_framework_PushKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (8.6 kB)\n",
      "Downloading pyobjc_framework_Quartz-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (227 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.2/227.2 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pyobjc_framework_QuickLookThumbnailing-10.3.1-py2.py3-none-any.whl (3.8 kB)\n",
      "Using cached pyobjc_framework_ReplayKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (10 kB)\n",
      "Using cached pyobjc_framework_SafariServices-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (7.5 kB)\n",
      "Using cached pyobjc_framework_SafetyKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (8.3 kB)\n",
      "Using cached pyobjc_framework_SceneKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (33 kB)\n",
      "Downloading pyobjc_framework_ScreenCaptureKit-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (11 kB)\n",
      "Using cached pyobjc_framework_ScreenSaver-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (8.0 kB)\n",
      "Using cached pyobjc_framework_ScreenTime-10.3.1-py2.py3-none-any.whl (3.4 kB)\n",
      "Using cached pyobjc_framework_ScriptingBridge-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (8.5 kB)\n",
      "Using cached pyobjc_framework_SearchKit-10.3.1-py2.py3-none-any.whl (3.3 kB)\n",
      "Downloading pyobjc_framework_Security-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (41 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/41.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pyobjc_framework_SecurityFoundation-10.3.1-py2.py3-none-any.whl (3.4 kB)\n",
      "Using cached pyobjc_framework_SecurityInterface-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (10 kB)\n",
      "Using cached pyobjc_framework_SensitiveContentAnalysis-10.3.1-py2.py3-none-any.whl (3.5 kB)\n",
      "Using cached pyobjc_framework_ServiceManagement-10.3.1-py2.py3-none-any.whl (4.9 kB)\n",
      "Using cached pyobjc_framework_SharedWithYou-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (9.1 kB)\n",
      "Using cached pyobjc_framework_SharedWithYouCore-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (8.9 kB)\n",
      "Downloading pyobjc_framework_ShazamKit-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (8.6 kB)\n",
      "Using cached pyobjc_framework_Social-10.3.1-py2.py3-none-any.whl (4.1 kB)\n",
      "Using cached pyobjc_framework_SoundAnalysis-10.3.1-py2.py3-none-any.whl (3.8 kB)\n",
      "Using cached pyobjc_framework_Speech-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (9.6 kB)\n",
      "Downloading pyobjc_framework_SpriteKit-10.3.1-cp310-cp310-macosx_10_9_universal2.whl (17 kB)\n",
      "Using cached pyobjc_framework_StoreKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (12 kB)\n",
      "Using cached pyobjc_framework_Symbols-10.3.1-py2.py3-none-any.whl (3.0 kB)\n",
      "Using cached pyobjc_framework_SyncServices-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (14 kB)\n",
      "Using cached pyobjc_framework_SystemConfiguration-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (21 kB)\n",
      "Using cached pyobjc_framework_SystemExtensions-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (9.1 kB)\n",
      "Using cached pyobjc_framework_ThreadNetwork-10.3.1-py2.py3-none-any.whl (3.4 kB)\n",
      "Using cached pyobjc_framework_UniformTypeIdentifiers-10.3.1-py2.py3-none-any.whl (4.5 kB)\n",
      "Using cached pyobjc_framework_UserNotifications-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (10 kB)\n",
      "Using cached pyobjc_framework_UserNotificationsUI-10.3.1-py2.py3-none-any.whl (3.5 kB)\n",
      "Using cached pyobjc_framework_VideoSubscriberAccount-10.3.1-py2.py3-none-any.whl (4.3 kB)\n",
      "Using cached pyobjc_framework_VideoToolbox-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (12 kB)\n",
      "Using cached pyobjc_framework_Virtualization-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (12 kB)\n",
      "Using cached pyobjc_framework_Vision-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (17 kB)\n",
      "Using cached pyobjc_framework_WebKit-10.3.1-cp36-abi3-macosx_11_0_universal2.whl (44 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached sentence_transformers-3.2.1-py3-none-any.whl (255 kB)\n",
      "Downloading numba-0.60.0-cp310-cp310-macosx_11_0_arm64.whl (2.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading llvmlite-0.43.0-cp310-cp310-macosx_11_0_arm64.whl (28.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.8/28.8 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: pyaudio, openai-whisper\n",
      "  Building wheel for pyaudio (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyaudio: filename=PyAudio-0.2.14-cp310-cp310-macosx_13_0_arm64.whl size=25694 sha256=647a17cc983594939203233334e725b1431095b94e4070feb60de827543c5841\n",
      "  Stored in directory: /Users/khoimai/Library/Caches/pip/wheels/d6/21/f4/0b51d41ba79e51b16295cbb096ec49f334792814d545b508c5\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20240930-py3-none-any.whl size=803321 sha256=f2c31f8ef0285b55e2523429f1aaedcc1397ce1b5198de37aadd273c4acd0f5c\n",
      "  Stored in directory: /Users/khoimai/Library/Caches/pip/wheels/dd/4a/1f/d1c4bf3b9133c8168fe617ed979cab7b14fe381d059ffb9d83\n",
      "Successfully built pyaudio openai-whisper\n",
      "Installing collected packages: pyaudio, requests, pyobjc-core, llvmlite, pyobjc-framework-Cocoa, numba, pyobjc-framework-WebKit, pyobjc-framework-Virtualization, pyobjc-framework-VideoSubscriberAccount, pyobjc-framework-UserNotifications, pyobjc-framework-UniformTypeIdentifiers, pyobjc-framework-ThreadNetwork, pyobjc-framework-SystemExtensions, pyobjc-framework-SystemConfiguration, pyobjc-framework-Symbols, pyobjc-framework-StoreKit, pyobjc-framework-Speech, pyobjc-framework-SoundAnalysis, pyobjc-framework-Social, pyobjc-framework-ShazamKit, pyobjc-framework-SharedWithYouCore, pyobjc-framework-ServiceManagement, pyobjc-framework-Security, pyobjc-framework-ScriptingBridge, pyobjc-framework-ScreenTime, pyobjc-framework-ScreenSaver, pyobjc-framework-SafariServices, pyobjc-framework-ReplayKit, pyobjc-framework-Quartz, pyobjc-framework-PushKit, pyobjc-framework-PreferencePanes, pyobjc-framework-PhotosUI, pyobjc-framework-Photos, pyobjc-framework-PencilKit, pyobjc-framework-PassKit, pyobjc-framework-OSAKit, pyobjc-framework-OpenDirectory, pyobjc-framework-NotificationCenter, pyobjc-framework-NetworkExtension, pyobjc-framework-Network, pyobjc-framework-NetFS, pyobjc-framework-NaturalLanguage, pyobjc-framework-MultipeerConnectivity, pyobjc-framework-MLCompute, pyobjc-framework-MetricKit, pyobjc-framework-Metal, pyobjc-framework-MediaToolbox, pyobjc-framework-MediaAccessibility, pyobjc-framework-MailKit, pyobjc-framework-libxpc, pyobjc-framework-libdispatch, pyobjc-framework-LatentSemanticMapping, pyobjc-framework-KernelManagement, pyobjc-framework-iTunesLibrary, pyobjc-framework-IOSurface, pyobjc-framework-IOBluetooth, pyobjc-framework-Intents, pyobjc-framework-InstallerPlugins, pyobjc-framework-InputMethodKit, pyobjc-framework-ImageCaptureCore, pyobjc-framework-HealthKit, pyobjc-framework-GameController, pyobjc-framework-GameCenter, pyobjc-framework-FSEvents, pyobjc-framework-FinderSync, pyobjc-framework-FileProvider, pyobjc-framework-ExternalAccessory, pyobjc-framework-ExtensionKit, pyobjc-framework-ExecutionPolicy, pyobjc-framework-ExceptionHandling, pyobjc-framework-EventKit, pyobjc-framework-DVDPlayback, pyobjc-framework-DiskArbitration, pyobjc-framework-DiscRecording, pyobjc-framework-DeviceCheck, pyobjc-framework-DataDetection, pyobjc-framework-CryptoTokenKit, pyobjc-framework-CoreWLAN, pyobjc-framework-CoreSpotlight, pyobjc-framework-CoreMotion, pyobjc-framework-CoreML, pyobjc-framework-CoreMIDI, pyobjc-framework-CoreMediaIO, pyobjc-framework-CoreMedia, pyobjc-framework-CoreLocation, pyobjc-framework-CoreHaptics, pyobjc-framework-CoreData, pyobjc-framework-CoreBluetooth, pyobjc-framework-CoreAudio, pyobjc-framework-Contacts, pyobjc-framework-ColorSync, pyobjc-framework-Collaboration, pyobjc-framework-ClassKit, pyobjc-framework-CFNetwork, pyobjc-framework-CallKit, pyobjc-framework-CalendarStore, pyobjc-framework-BusinessChat, pyobjc-framework-BackgroundAssets, pyobjc-framework-AVRouting, pyobjc-framework-Automator, pyobjc-framework-AutomaticAssessmentConfiguration, pyobjc-framework-AuthenticationServices, pyobjc-framework-AudioVideoBridging, pyobjc-framework-AppTrackingTransparency, pyobjc-framework-AppleScriptObjC, pyobjc-framework-AppleScriptKit, pyobjc-framework-AdSupport, pyobjc-framework-AdServices, pyobjc-framework-AddressBook, pyobjc-framework-Accounts, openai-whisper, pyobjc-framework-Vision, pyobjc-framework-VideoToolbox, pyobjc-framework-UserNotificationsUI, pyobjc-framework-SyncServices, pyobjc-framework-SpriteKit, pyobjc-framework-SharedWithYou, pyobjc-framework-SensitiveContentAnalysis, pyobjc-framework-SecurityInterface, pyobjc-framework-SecurityFoundation, pyobjc-framework-ScreenCaptureKit, pyobjc-framework-SceneKit, pyobjc-framework-SafetyKit, pyobjc-framework-QuickLookThumbnailing, pyobjc-framework-OSLog, pyobjc-framework-ModelIO, pyobjc-framework-MetalPerformanceShaders, pyobjc-framework-MetalKit, pyobjc-framework-MetalFX, pyobjc-framework-MediaLibrary, pyobjc-framework-MapKit, pyobjc-framework-LocalAuthentication, pyobjc-framework-LinkPresentation, pyobjc-framework-IOBluetoothUI, pyobjc-framework-IntentsUI, pyobjc-framework-InstantMessage, pyobjc-framework-GameKit, pyobjc-framework-FileProviderUI, pyobjc-framework-DiscRecordingUI, pyobjc-framework-CoreText, pyobjc-framework-CoreServices, pyobjc-framework-CoreAudioKit, pyobjc-framework-ContactsUI, pyobjc-framework-CloudKit, pyobjc-framework-BrowserEngineKit, pyobjc-framework-AVKit, pyobjc-framework-AVFoundation, pyobjc-framework-Accessibility, datasets, sentence-transformers, pyobjc-framework-SearchKit, pyobjc-framework-PHASE, pyobjc-framework-MetalPerformanceShadersGraph, pyobjc-framework-MediaPlayer, pyobjc-framework-LocalAuthenticationEmbeddedUI, pyobjc-framework-LaunchServices, pyobjc-framework-GameplayKit, pyobjc-framework-DictionaryServices, pyobjc-framework-Cinematic, pyobjc-framework-ApplicationServices, evaluate, pyobjc, setfit, pyttsx3\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "  Attempting uninstall: datasets\n",
      "    Found existing installation: datasets 2.14.4\n",
      "    Uninstalling datasets-2.14.4:\n",
      "      Successfully uninstalled datasets-2.14.4\n",
      "  Attempting uninstall: sentence-transformers\n",
      "    Found existing installation: sentence-transformers 2.7.0\n",
      "    Uninstalling sentence-transformers-2.7.0:\n",
      "      Successfully uninstalled sentence-transformers-2.7.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab-server 2.25.2 requires jsonschema>=4.18.0, but you have jsonschema 4.16.0 which is incompatible.\n",
      "ray 2.0.1 requires grpcio<=1.43.0,>=1.42.0; python_version >= \"3.10\", but you have grpcio 1.64.1 which is incompatible.\n",
      "ray 2.0.1 requires protobuf<4.0.0,>=3.15.3, but you have protobuf 4.25.3 which is incompatible.\n",
      "tensorboard 2.10.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 4.25.3 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed datasets-3.0.2 evaluate-0.4.3 llvmlite-0.43.0 numba-0.60.0 openai-whisper-20240930 pyaudio-0.2.14 pyobjc-10.3.1 pyobjc-core-10.3.1 pyobjc-framework-AVFoundation-10.3.1 pyobjc-framework-AVKit-10.3.1 pyobjc-framework-AVRouting-10.3.1 pyobjc-framework-Accessibility-10.3.1 pyobjc-framework-Accounts-10.3.1 pyobjc-framework-AdServices-10.3.1 pyobjc-framework-AdSupport-10.3.1 pyobjc-framework-AddressBook-10.3.1 pyobjc-framework-AppTrackingTransparency-10.3.1 pyobjc-framework-AppleScriptKit-10.3.1 pyobjc-framework-AppleScriptObjC-10.3.1 pyobjc-framework-ApplicationServices-10.3.1 pyobjc-framework-AudioVideoBridging-10.3.1 pyobjc-framework-AuthenticationServices-10.3.1 pyobjc-framework-AutomaticAssessmentConfiguration-10.3.1 pyobjc-framework-Automator-10.3.1 pyobjc-framework-BackgroundAssets-10.3.1 pyobjc-framework-BrowserEngineKit-10.3.1 pyobjc-framework-BusinessChat-10.3.1 pyobjc-framework-CFNetwork-10.3.1 pyobjc-framework-CalendarStore-10.3.1 pyobjc-framework-CallKit-10.3.1 pyobjc-framework-Cinematic-10.3.1 pyobjc-framework-ClassKit-10.3.1 pyobjc-framework-CloudKit-10.3.1 pyobjc-framework-Cocoa-10.3.1 pyobjc-framework-Collaboration-10.3.1 pyobjc-framework-ColorSync-10.3.1 pyobjc-framework-Contacts-10.3.1 pyobjc-framework-ContactsUI-10.3.1 pyobjc-framework-CoreAudio-10.3.1 pyobjc-framework-CoreAudioKit-10.3.1 pyobjc-framework-CoreBluetooth-10.3.1 pyobjc-framework-CoreData-10.3.1 pyobjc-framework-CoreHaptics-10.3.1 pyobjc-framework-CoreLocation-10.3.1 pyobjc-framework-CoreMIDI-10.3.1 pyobjc-framework-CoreML-10.3.1 pyobjc-framework-CoreMedia-10.3.1 pyobjc-framework-CoreMediaIO-10.3.1 pyobjc-framework-CoreMotion-10.3.1 pyobjc-framework-CoreServices-10.3.1 pyobjc-framework-CoreSpotlight-10.3.1 pyobjc-framework-CoreText-10.3.1 pyobjc-framework-CoreWLAN-10.3.1 pyobjc-framework-CryptoTokenKit-10.3.1 pyobjc-framework-DVDPlayback-10.3.1 pyobjc-framework-DataDetection-10.3.1 pyobjc-framework-DeviceCheck-10.3.1 pyobjc-framework-DictionaryServices-10.3.1 pyobjc-framework-DiscRecording-10.3.1 pyobjc-framework-DiscRecordingUI-10.3.1 pyobjc-framework-DiskArbitration-10.3.1 pyobjc-framework-EventKit-10.3.1 pyobjc-framework-ExceptionHandling-10.3.1 pyobjc-framework-ExecutionPolicy-10.3.1 pyobjc-framework-ExtensionKit-10.3.1 pyobjc-framework-ExternalAccessory-10.3.1 pyobjc-framework-FSEvents-10.3.1 pyobjc-framework-FileProvider-10.3.1 pyobjc-framework-FileProviderUI-10.3.1 pyobjc-framework-FinderSync-10.3.1 pyobjc-framework-GameCenter-10.3.1 pyobjc-framework-GameController-10.3.1 pyobjc-framework-GameKit-10.3.1 pyobjc-framework-GameplayKit-10.3.1 pyobjc-framework-HealthKit-10.3.1 pyobjc-framework-IOBluetooth-10.3.1 pyobjc-framework-IOBluetoothUI-10.3.1 pyobjc-framework-IOSurface-10.3.1 pyobjc-framework-ImageCaptureCore-10.3.1 pyobjc-framework-InputMethodKit-10.3.1 pyobjc-framework-InstallerPlugins-10.3.1 pyobjc-framework-InstantMessage-10.3.1 pyobjc-framework-Intents-10.3.1 pyobjc-framework-IntentsUI-10.3.1 pyobjc-framework-KernelManagement-10.3.1 pyobjc-framework-LatentSemanticMapping-10.3.1 pyobjc-framework-LaunchServices-10.3.1 pyobjc-framework-LinkPresentation-10.3.1 pyobjc-framework-LocalAuthentication-10.3.1 pyobjc-framework-LocalAuthenticationEmbeddedUI-10.3.1 pyobjc-framework-MLCompute-10.3.1 pyobjc-framework-MailKit-10.3.1 pyobjc-framework-MapKit-10.3.1 pyobjc-framework-MediaAccessibility-10.3.1 pyobjc-framework-MediaLibrary-10.3.1 pyobjc-framework-MediaPlayer-10.3.1 pyobjc-framework-MediaToolbox-10.3.1 pyobjc-framework-Metal-10.3.1 pyobjc-framework-MetalFX-10.3.1 pyobjc-framework-MetalKit-10.3.1 pyobjc-framework-MetalPerformanceShaders-10.3.1 pyobjc-framework-MetalPerformanceShadersGraph-10.3.1 pyobjc-framework-MetricKit-10.3.1 pyobjc-framework-ModelIO-10.3.1 pyobjc-framework-MultipeerConnectivity-10.3.1 pyobjc-framework-NaturalLanguage-10.3.1 pyobjc-framework-NetFS-10.3.1 pyobjc-framework-Network-10.3.1 pyobjc-framework-NetworkExtension-10.3.1 pyobjc-framework-NotificationCenter-10.3.1 pyobjc-framework-OSAKit-10.3.1 pyobjc-framework-OSLog-10.3.1 pyobjc-framework-OpenDirectory-10.3.1 pyobjc-framework-PHASE-10.3.1 pyobjc-framework-PassKit-10.3.1 pyobjc-framework-PencilKit-10.3.1 pyobjc-framework-Photos-10.3.1 pyobjc-framework-PhotosUI-10.3.1 pyobjc-framework-PreferencePanes-10.3.1 pyobjc-framework-PushKit-10.3.1 pyobjc-framework-Quartz-10.3.1 pyobjc-framework-QuickLookThumbnailing-10.3.1 pyobjc-framework-ReplayKit-10.3.1 pyobjc-framework-SafariServices-10.3.1 pyobjc-framework-SafetyKit-10.3.1 pyobjc-framework-SceneKit-10.3.1 pyobjc-framework-ScreenCaptureKit-10.3.1 pyobjc-framework-ScreenSaver-10.3.1 pyobjc-framework-ScreenTime-10.3.1 pyobjc-framework-ScriptingBridge-10.3.1 pyobjc-framework-SearchKit-10.3.1 pyobjc-framework-Security-10.3.1 pyobjc-framework-SecurityFoundation-10.3.1 pyobjc-framework-SecurityInterface-10.3.1 pyobjc-framework-SensitiveContentAnalysis-10.3.1 pyobjc-framework-ServiceManagement-10.3.1 pyobjc-framework-SharedWithYou-10.3.1 pyobjc-framework-SharedWithYouCore-10.3.1 pyobjc-framework-ShazamKit-10.3.1 pyobjc-framework-Social-10.3.1 pyobjc-framework-SoundAnalysis-10.3.1 pyobjc-framework-Speech-10.3.1 pyobjc-framework-SpriteKit-10.3.1 pyobjc-framework-StoreKit-10.3.1 pyobjc-framework-Symbols-10.3.1 pyobjc-framework-SyncServices-10.3.1 pyobjc-framework-SystemConfiguration-10.3.1 pyobjc-framework-SystemExtensions-10.3.1 pyobjc-framework-ThreadNetwork-10.3.1 pyobjc-framework-UniformTypeIdentifiers-10.3.1 pyobjc-framework-UserNotifications-10.3.1 pyobjc-framework-UserNotificationsUI-10.3.1 pyobjc-framework-VideoSubscriberAccount-10.3.1 pyobjc-framework-VideoToolbox-10.3.1 pyobjc-framework-Virtualization-10.3.1 pyobjc-framework-Vision-10.3.1 pyobjc-framework-WebKit-10.3.1 pyobjc-framework-iTunesLibrary-10.3.1 pyobjc-framework-libdispatch-10.3.1 pyobjc-framework-libxpc-10.3.1 pyttsx3-2.98 requests-2.32.3 sentence-transformers-3.2.1 setfit-1.1.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "130843.49s - pydevd: Sending message related to process being replaced timed-out after 5 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.2)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.2.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.4)\n",
      "Requirement already satisfied: jinja2 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
      "Requirement already satisfied: setuptools in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2022.9.24)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Attempting uninstall: en-core-web-sm\n",
      "    Found existing installation: en-core-web-sm 2.2.0\n",
      "    Uninstalling en-core-web-sm-2.2.0:\n",
      "      Successfully uninstalled en-core-web-sm-2.2.0\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "%pip install ipywidgets pyaudio openai-whisper pyttsx3 setfit spacy jellyfish\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code for the simulated elevator is provided below. The elevator is displayed using simple widgets (where the current floor is shown in green). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "import time, random, string, threading\n",
    "from typing import List, Tuple, Dict, Set\n",
    "\n",
    "class BasicElevator:\n",
    "    \"\"\"Elevator simulated using a GUI\"\"\"\n",
    "    \n",
    "    def __init__(self, start_floor:int =1, nb_floors=10):\n",
    "        \"\"\"Initialised a new elevator, placed on the first floor\"\"\"\n",
    "        \n",
    "        # Current floor of the elevator\n",
    "        self.cur_floor: int = start_floor\n",
    "\n",
    "        # (Possibly empty) list of next floor stops to reach \n",
    "        self.next_stops : List[int] = []\n",
    "        \n",
    "        # Building the basic GUI showing the elevator\n",
    "        display(self._build_gui(nb_floors))\n",
    "\n",
    "        # Starts the thread executing the movements\n",
    "        thread = threading.Thread(target=self.elevator_move_thread)\n",
    "        thread.start()     \n",
    "            \n",
    "    def move_to_floor(self, floor_number : int):\n",
    "        \"\"\"Move to a given floor (by adding it to a stack of floors to reach)\"\"\"\n",
    "        \n",
    "        if floor_number < 1 or floor_number > len(self.floors):\n",
    "            raise RuntimeError(\"Floor number must be between 1 and %i\"%len(self.floors))\n",
    "\n",
    "        self.next_stops.append(floor_number)\n",
    "        \n",
    "        \n",
    "    def stop(self):\n",
    "        \"\"\"Stops all movements of the elevator\"\"\"\n",
    "        self.next_stops.clear()\n",
    "\n",
    "    def _build_gui(self, nb_floors):\n",
    "        \"\"\"Creates the GUI for the elevator, with a status label and a visual representation\n",
    "        of the floors, where the current floor is indicated in green.\"\"\"\n",
    "\n",
    "        # Displaying the current status of the elevator (still or going up or down)\n",
    "        status_label = widgets.HTML(\"<b>Status</b>: \")\n",
    "        self.status = widgets.Label(\"Still\")\n",
    "        status_box = widgets.HBox([status_label, self.status])\n",
    "\n",
    "        # Displaying the floors on a vertical axis\n",
    "        self.floors = []\n",
    "        floor_layout = widgets.Layout(width='50px', height='30px', border='2px solid black',justify_content=\"center\")\n",
    "        for i in range(1, nb_floors+1):\n",
    "            floor = widgets.Label(value=str(i), layout=floor_layout)\n",
    "            floor.style = {\"background\":(\"white\" if i!=self.cur_floor else \"lightgreen\")}\n",
    "            self.floors.append(floor)\n",
    "\n",
    "        # Create a vertical box container to hold the boxes\n",
    "        vbox = widgets.VBox([status_box] + self.floors[::-1])\n",
    "        return vbox\n",
    "    \n",
    "\n",
    "    def elevator_move_thread(self, speed=1.0, latency=0.1):\n",
    "        \"\"\"Trigger a movement of the elevator if the list of next stops is not \n",
    "        empty. The movement continues until all goals are reached.\"\"\"\n",
    "\n",
    "        while True:\n",
    "            while self.next_stops:\n",
    "                if self.cur_floor == self.next_stops[0]:\n",
    "                    del self.next_stops[0]\n",
    "                    continue\n",
    "                if self.cur_floor < self.next_stops[0]:\n",
    "                    next_floor = self.cur_floor+1\n",
    "                    self.status.value = \"UP\"\n",
    "                elif self.cur_floor > self.next_stops[0]:\n",
    "                    next_floor = self.cur_floor-1\n",
    "                    self.status.value = \"DOWN\"\n",
    "                time.sleep(speed)   \n",
    "                self.floors[self.cur_floor-1].style.background = \"white\"\n",
    "                self.floors[next_floor-1].style.background = \"lightgreen\"\n",
    "                self.cur_floor = next_floor\n",
    "            self.status.value = \"Still\"\n",
    "            \n",
    "            # Wait loop (until we have a goal in self.next_stops)\n",
    "            time.sleep(latency)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The elevator can be easily controlled through the functions `move_to_floor` and `stop`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa9722483ae34d4a8f8361354df37472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(HTML(value='<b>Status</b>: '), Label(value='Still'))), Label(value='10', layout=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "elevator = BasicElevator()\n",
    "elevator.move_to_floor(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now make our elevator controllable through a speech interface instead of using function calls.\n",
    "\n",
    "## Speech interface\n",
    "\n",
    "First, make sure that you have installed `pyaudio` (for audio processing), `whisper` (for speech recognition), and `pyttsx3` (for speech synthesis).\n",
    "\n",
    "The `TalkingElevator` class below extends the basic simulated elevator with speech input and output. \n",
    "\n",
    "Upon clicking on the recording button, speech is recorded from the user's microphone, and continues until the stop button is clicked. The speech recognition engine `Whisper` from OpenAI is then employed to transcribe the spoken input (either on GPU, if you have a GPU on your machine, or on CPU). The transcription result is then sent to the `process_input` function, which is responsible for determining the system response. \n",
    "\n",
    "We are going to focus on implementing this `process_input` method. Note this system reaction to new user inputs may comprise both verbal responses (to be uttered by the system through the `_say_to_user` method) and physical actions (through the `move_to_floor` and `stop` methods)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import threading, time\n",
    "import numpy as np\n",
    "from typing import List, Tuple, Dict, Set\n",
    "import whisper, pyaudio, pyttsx3\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "class TalkingElevator(BasicElevator):\n",
    "    \"\"\"Extension of the simulated elevator with a speech interface\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        print(\"Loading TTS and ASR models\", end=\"...\", flush=True)\n",
    "        self.tts_engine = pyttsx3.init()  \n",
    "        self.asr_engine = whisper.load_model(\"small.en\")\n",
    "        print(\"Done\")\n",
    "        \n",
    "        # Initializing the GUI\n",
    "        BasicElevator.__init__(self)\n",
    "\n",
    "        # Starts the dialogue\n",
    "        self.dialogue_history = []\n",
    "        self._say_to_user(\"Hi, what can I do for you today?\")\n",
    "    \n",
    "\n",
    "    def process_input(self, user_input: str, conf_score:float=1.0):\n",
    "        \"\"\"Processes the (transcribed) user input, and respond appropriately \n",
    "        (through a verbal response and possibly also an action, such as moving floors)\"\"\"\n",
    "\n",
    "        self._add_to_dialogue_history(user_input, speaker=\"user\", conf_score=conf_score)\n",
    "\n",
    "        # Dummy response. Should be replaced by the actual dialogue behaviour\n",
    "        self._say_to_user(\"Sorry, I don't understand you, pal\")\n",
    "\n",
    "    \n",
    "    def _say_to_user(self, system_response: str):\n",
    "        \"\"\"Say something back to the user, and add the dialogue turn to the history. The \n",
    "        synthesis is done using the pyttsx3 library.\"\"\"\n",
    "\n",
    "        self._add_to_dialogue_history(system_response, speaker=\"elevator\")\n",
    "        \n",
    "        # Stopping current TTS if one is active\n",
    "        try:\n",
    "            self.tts_engine.endLoop()\n",
    "        except:\n",
    "            pass\n",
    "        self.tts_engine.say(system_response)\n",
    "        self.tts_engine.runAndWait()\n",
    "\n",
    "\n",
    "    def _add_to_dialogue_history(self, turn:str , speaker:str, conf_score:float=1.0):\n",
    "        \"\"\"Adds a new (user or system) turn to the dialogue history list, and displays it\n",
    "         on the chat window displaying the turns\"\"\"\n",
    "\n",
    "        self.dialogue_history.append({\"speaker\":speaker, \"text\":turn, \n",
    "                                      \"conf_score\":conf_score, \"timesamp\":time.time()})\n",
    "        \n",
    "        self.history_area.value += \"&nbsp;<strong>%s</strong>:  %s\"%(speaker.title(), turn)\n",
    "        if conf_score < 1.0:\n",
    "            self.history_area.value += \" (%.2f)\"%(conf_score)\n",
    "        self.history_area.value += \"<br>\"\n",
    "   \n",
    "   \n",
    "    def _build_gui(self, nb_floors):\n",
    "        \"\"\"GUI for the Talking elevator, comprising (beyond the simulated elevator from \n",
    "        BasicElevator) a chat window showing the dialogue turns, and buttons to record\n",
    "        the user input. \n",
    "        The user should first click on the record button, then on stop when they have finished.\n",
    "        Once the stop button is clicked, the audio is transcribed by Whisper, and finally \n",
    "        forwarded to the process_input function.\"\"\"\n",
    "\n",
    "        core_gui = BasicElevator._build_gui(self, nb_floors)\n",
    "\n",
    "        self.frames = []\n",
    "        self.recording = False\n",
    "\n",
    "        def record(chunk_size=1024):\n",
    "            \"\"\"Record audio chunks to a buffer.\"\"\"\n",
    "            self.recording = True\n",
    "            p = pyaudio.PyAudio()\n",
    "            stream = p.open(format=pyaudio.paInt16, channels=1, rate=16000, input=True, \n",
    "                            frames_per_buffer=chunk_size)\n",
    "            while self.recording:\n",
    "                self.frames.append(stream.read(chunk_size))\n",
    "            stream.close()\n",
    "\n",
    "        def on_record_button_clicked(b):\n",
    "            \"Starts the recording\"\n",
    "            record_button.disabled=True\n",
    "            stop_button.disabled=False\n",
    "            self.frames = []  # Clear previous recordings\n",
    "            thread = threading.Thread(target=record)\n",
    "            thread.start()\n",
    "\n",
    "        def on_stop_button_clicked(b):\n",
    "            \"stops the recording, runs Whisper, and forward the result to process_input\"\n",
    "            self.recording = False\n",
    "            record_button.disabled=False\n",
    "            stop_button.disabled=True\n",
    "            audio_data = np.frombuffer(b\"\".join(self.frames), np.int16).astype(np.float32) * (1 / 32768.0)\n",
    "            output = self.asr_engine.transcribe(audio_data)\n",
    "\n",
    "            # We define the confidence score based on the log-probabilities\n",
    "            conf_score = np.exp(np.mean([segment[\"avg_logprob\"] for segment in output[\"segments\"]]))\n",
    "            # (and we push those up a bit, as the Whisper scores seem too low)\n",
    "            conf_score = min(1, conf_score*1.2)\n",
    "\n",
    "            # Finally, we process the input\n",
    "            self.process_input(output[\"text\"], conf_score)\n",
    "\n",
    "        # The record and stop buttons\n",
    "        record_button = widgets.Button(icon=\"microphone\")\n",
    "        stop_button = widgets.Button(icon=\"stop\", disabled=True)\n",
    "        record_button.on_click(on_record_button_clicked)\n",
    "        stop_button.on_click(on_stop_button_clicked)\n",
    "        \n",
    "        # The chat area\n",
    "        self.history_area = widgets.HTML(layout=widgets.Layout(width=\"600px\", height=\"300px\", \n",
    "                                                               border='1px solid black', overflow='scroll'))\n",
    "\n",
    "        # The right side of the GUI\n",
    "        right_side = widgets.VBox([widgets.Label(\"\"), self.history_area, widgets.HBox([record_button, stop_button])])\n",
    "        \n",
    "        extended_gui = widgets.HBox([core_gui, right_side])\n",
    "        return extended_gui\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading TTS and ASR models...Done\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89e09784480f4a278884cb51f051d7fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(HBox(children=(HTML(value='<b>Status</b>: '), Label(value='Still'))), Label(valu…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "elevator = TalkingElevator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hope that the speech recognition and speech synthesis will work correctly -- if it isn't the case, do let us know ! (audio processing in Python can be quite tricky and will work differently from OS to OS). [^1]\n",
    "\n",
    "[^1]: If you are running on Linux and the TTS is not working, install the following packages on your machine: `sudo apt update && sudo apt install espeak ffmpeg libespeak1`\n",
    "\n",
    "**Note**: The current implementation reloads the TTS and ASR models every time, which means that you may run into a \"CUDA: out of memory\" error if you reinitialise the `TalkingElevator` many times. If this happens, simply restart the Python kernel, which will clear the memory on both the CPU and the GPU. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Intent recognition\n",
    "\n",
    "We wish our talking elevator to support the following functionalities:\n",
    " \n",
    "- If the user express a wish to go to floor $X$ (where $X$ is an integer value between 1 and 10), the elevator should go to that floor. The interface should allow for several ways to express a given intent, such as \"_Please go to the $X$-th floor_\" or \"_Floor $X$, please_\".\n",
    "- The user requests can also be relative, for instance \"_Go one floor up_\".\n",
    "- The elevator should provide _grounding_ feedback to the user. For instance, it should respond \"_Ok, going to the $X$-th floor_\" after a user request to move to $X$.  \n",
    "- The elevator should handle misunderstandings and uncertainties, e.g. by requesting the user to repeat, or asking the user to confirm if the intent is uncertain (say, when its confidence score is lower than 0.5). \n",
    "- The elevator should also allow the user to ask where the office of a given employee is located. For instance, the user could ask \"_where is Erik Velldal's office?_\", and the elevator would provide a response such as \"_The office of Erik Velldal is on the 4th floor. Do you wish to go there?_\".  We provide you with the office numbers of a small set of IFI employees in the `OFFICES` dictionary (see below).\n",
    "- The elevator should also be able to inform the user about the current floor (such as replying to \"_Which floor are we on?_\" or \"_Are we on the 5th floor?_\"). \n",
    "- Finally, if the user asks the elevator to stop (or if the user says \"_no_\" after a grounding feedback \"_Ok, going to floor $X$._\"), the elevator should stop, and ask for clarification regarding the actual user intent. \n",
    "\n",
    "To implement this conversational behaviour, we will rely on a classical NLU-based approach in which we will recognise the user _intent_, and then determine a response based on the recognised intent(s). \n",
    "\n",
    "__Task 1.1__ (1 point): You first need to define a list of user intents that cover the kinds of user inputs you expect to observe in this talking elevator, such as `RequestMoveToFloor` or `Confirm`. This is a design question, and there is no obvious right or wrong answer. Define below the intents you want to cover, along with an explanation and a few examples of user inputs for each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Provide here the list of intent classes you have defined, together with an explanation and a few examples -->\n",
    "**Answer:**\n",
    "\n",
    "1. `RequestMoveToFloor`: This intent is used when the user wants to move to a specific floor. Examples: \"Please go to the 5th floor\", \"Floor 3, please\", \"I want to go to the 7th floor\".\n",
    "2. `RequestMoveRelative`: This intent is used when the user wants to move to a floor relative to the current floor. Examples: \"Go one floor up\", \"Move two floors down\", \"Take me to the floor above\".\n",
    "3. `RequestOfficeLocation`: This intent is used when the user wants to know the location of an employee's office. Examples: \"Where is Erik's office?\", \"Can you tell me where the office of Erik is?\", \"I need to know where Erik's office is\".\n",
    "4. `RequestCurrentFloor`: This intent is used when the user wants to know the current floor. Examples: \"Which floor are we on?\", \"Are we on the 5th floor?\", \"Can you tell me the current floor?\".\n",
    "5. `Confirm`: This intent is used when the user confirms the elevator's response. Examples: \"Yes\", \"That's correct\", \"I confirm\".\n",
    "6. `Stop`: This intent is used when the user wants the elevator to stop. Examples: \"Stop\", \"I want to stop\", \"Please stop\".\n",
    "7. `Repeat`: This intent is used when the user wants the elevator to repeat the last response. Examples: \"Can you repeat that?\", \"I didn't hear you\", \"What did you say?\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 1.2__ (1 points): We wish to build a classifier any user input to a probability distribution over those intents, and start by creating a small, synthetic training set. Make a list of about 100 user utterances, each labelled with an intent defined above. You can \"make up\" those utterances yourself, or ask someone else to come with alternative formulations if you lack inspiration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelled_utterances = [\n",
    "    # Move Intent\n",
    "    (\"Go to floor 1\", \"Move\"),\n",
    "    (\"Take me to floor 2\", \"Move\"),\n",
    "    (\"Please go up to the 5th floor\", \"Move\"),\n",
    "    (\"Take me to the top floor\", \"Move\"),\n",
    "    (\"I’d like to go to floor 3\", \"Move\"),\n",
    "    (\"Move to floor 4\", \"Move\"),\n",
    "    (\"Take us to the first floor\", \"Move\"),\n",
    "    (\"Bring me to the highest floor\", \"Move\"),\n",
    "    (\"Could we go to floor 6?\", \"Move\"),\n",
    "    (\"Can you take me to floor 8?\", \"Move\"),\n",
    "    (\"Please move to floor 7\", \"Move\"),\n",
    "    (\"I’d like to go down to the first floor\", \"Move\"),\n",
    "    (\"Take us up to floor 10\", \"Move\"),\n",
    "    (\"Let's go to floor 9\", \"Move\"),\n",
    "    (\"Bring me to floor 2\", \"Move\"),\n",
    "    (\"Elevator, please move to floor 3\", \"Move\"),\n",
    "    (\"Take me down to the ground floor\", \"Move\"),\n",
    "    (\"Take me up a floor\", \"Move\"),\n",
    "    (\"Let's head to floor 5\", \"Move\"),\n",
    "    (\"I want to go to floor 1\", \"Move\"),\n",
    "    (\"Take me to the basement\", \"Move\"),\n",
    "    (\"Could you take me down?\", \"Move\"),\n",
    "    (\"Let’s head down\", \"Move\"),\n",
    "    (\"Will you take me to the rooftop?\", \"Move\"),\n",
    "    (\"I'd like to visit floor 7\", \"Move\"),\n",
    "    (\"Could you stop at floor 3?\", \"Move\"),\n",
    "    (\"Take me to the middle floor\", \"Move\"),\n",
    "    (\"Bring me down to the lobby\", \"Move\"),\n",
    "    (\"Take me down to floor 2\", \"Move\"),\n",
    "    (\"Let's ride to floor 6\", \"Move\"),\n",
    "    (\"Please go up to floor 4\", \"Move\"),\n",
    "    (\"Take us down to the entrance\", \"Move\"),\n",
    "    (\"Elevator, take me to floor 8\", \"Move\"),\n",
    "    (\"Go up a floor, please\", \"Move\"),\n",
    "    (\"Take us to floor 3\", \"Move\"),\n",
    "    (\"Let's stop at floor 5\", \"Move\"),\n",
    "    (\"Move to floor 10\", \"Move\"),\n",
    "    (\"Let’s reach the top floor\", \"Move\"),\n",
    "    (\"Let's proceed to floor 4\", \"Move\"),\n",
    "    (\"Bring us to the lowest level\", \"Move\"),\n",
    "    (\"I'd like to head up to floor 9\", \"Move\"),\n",
    "    (\"Let’s go to floor 1\", \"Move\"),\n",
    "    (\"Head to the second level\", \"Move\"),\n",
    "\n",
    "    # Stop Intent\n",
    "    (\"Can you stop here?\", \"Stop\"),\n",
    "    (\"Stop the elevator\", \"Stop\"),\n",
    "    (\"Stop moving\", \"Stop\"),\n",
    "    (\"Stop at the next floor\", \"Stop\"),\n",
    "    (\"Please stop\", \"Stop\"),\n",
    "    (\"Stop the elevator at once\", \"Stop\"),\n",
    "    (\"End the ride\", \"Stop\"),\n",
    "    (\"Stop right here\", \"Stop\"),\n",
    "    (\"Stop the lift\", \"Stop\"),\n",
    "    (\"Can you wait here?\", \"Stop\"),\n",
    "    (\"Stop immediately\", \"Stop\"),\n",
    "    (\"Let’s halt here\", \"Stop\"),\n",
    "    (\"Stop the elevator for me\", \"Stop\"),\n",
    "    (\"Elevator, stop now\", \"Stop\"),\n",
    "    (\"Can you pause here?\", \"Stop\"),\n",
    "\n",
    "    # Status Inquiry Intent\n",
    "    (\"What floor am I on?\", \"Status Inquiry\"),\n",
    "    (\"Which floor are we at now?\", \"Status Inquiry\"),\n",
    "    (\"Are we moving?\", \"Status Inquiry\"),\n",
    "    (\"Is the elevator moving?\", \"Status Inquiry\"),\n",
    "    (\"Tell me the current floor\", \"Status Inquiry\"),\n",
    "    (\"Is this elevator moving up?\", \"Status Inquiry\"),\n",
    "    (\"Where are we now?\", \"Status Inquiry\"),\n",
    "    (\"Which floor are you at?\", \"Status Inquiry\"),\n",
    "    (\"What’s our current location?\", \"Status Inquiry\"),\n",
    "    (\"Are we on the main floor?\", \"Status Inquiry\"),\n",
    "    (\"Where is the elevator now?\", \"Status Inquiry\"),\n",
    "    (\"Are we on the way up?\", \"Status Inquiry\"),\n",
    "    (\"What’s the highest floor here?\", \"Status Inquiry\"),\n",
    "    (\"Where are we headed?\", \"Status Inquiry\"),\n",
    "    (\"Are we there yet?\", \"Status Inquiry\"),\n",
    "    (\"What floor are we passing?\", \"Status Inquiry\"),\n",
    "    (\"Are we close to floor 7?\", \"Status Inquiry\"),\n",
    "    (\"Which floor are you on?\", \"Status Inquiry\"),\n",
    "    (\"Is this the top floor?\", \"Status Inquiry\"),\n",
    "\n",
    "    # Greeting/Exit Intent\n",
    "    (\"Hello\", \"Greeting/Exit\"),\n",
    "    (\"Goodbye\", \"Greeting/Exit\"),\n",
    "    (\"Hello there!\", \"Greeting/Exit\"),\n",
    "    (\"Hi\", \"Greeting/Exit\"),\n",
    "    (\"Bye\", \"Greeting/Exit\"),\n",
    "    (\"Hey there\", \"Greeting/Exit\"),\n",
    "    (\"Nice to meet you, elevator!\", \"Greeting/Exit\"),\n",
    "    (\"Good afternoon\", \"Greeting/Exit\"),\n",
    "\n",
    "    # OutOfCoverage Intent\n",
    "    (\"I don’t need a ride\", \"OutOfCoverage\"),\n",
    "    (\"Close the door\", \"OutOfCoverage\"),\n",
    "    (\"Let's take the stairs\", \"OutOfCoverage\"),\n",
    "    (\"How many floors are there?\", \"OutOfCoverage\"),\n",
    "    (\"Are you on a break?\", \"OutOfCoverage\"),\n",
    "    (\"I don't need the elevator\", \"OutOfCoverage\"),\n",
    "    (\"Is the elevator moving fast?\", \"OutOfCoverage\"),\n",
    "    (\"Are you stopping at every floor?\", \"OutOfCoverage\"),\n",
    "    (\"Is anyone else here?\", \"OutOfCoverage\"),\n",
    "    (\"I really like the IN4080 course\", \"OutOfCoverage\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train an intent classifier based on the labelled utterances you have defined. To do so, we will rely on the [SetFit](https://huggingface.co/docs/setfit/index) library, which allows one to easily train a text classification model from few examples by fine-tuning a sentence-transformer model (like the ones we used in oblig 2 and 3). Make sure that the `setfit` library is installed (`pip install setfit`).\n",
    "\n",
    "Read the [Setfit quickstart guide](https://huggingface.co/docs/setfit/quickstart) to find out how to use the library.\n",
    "\n",
    "__Task 1.3__ (2 points): Implement the `__init__`, `train` and `get_intent_distrib` methods of the `IntentClassifier` class below. The classifier should rely on a `Setfit` model trained on the labelled utterances you have already defined. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "/Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:4: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  if not hasattr(tensorboard, \"__version__\") or LooseVersion(\n",
      "/Users/khoimai/.pyenv/versions/3.10.10/lib/python3.10/site-packages/torch/utils/tensorboard/__init__.py:6: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.\n",
      "  ) < LooseVersion(\"1.15\"):\n"
     ]
    }
   ],
   "source": [
    "from setfit import SetFitModel, Trainer, TrainingArguments, sample_dataset\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Initializing a new SetFit model\n",
    "model = SetFitModel.from_pretrained(\"BAAI/bge-small-en-v1.5\", labels=[\"negative\", \"positive\"])\n",
    "\n",
    "# Preparing the dataset\n",
    "dataset = load_dataset(\"SetFit/sst2\")\n",
    "train_dataset = sample_dataset(dataset[\"train\"], label_column=\"label\", num_samples=8)\n",
    "test_dataset = dataset[\"test\"]\n",
    "\n",
    "# Preparing the training arguments\n",
    "args = TrainingArguments(\n",
    "    batch_size=32,\n",
    "    num_epochs=10,\n",
    ")\n",
    "\n",
    "# Preparing the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=args,\n",
    "    train_dataset=train_dataset,\n",
    ")\n",
    "trainer.train()\n",
    "\n",
    "# Evaluating\n",
    "metrics = trainer.evaluate(test_dataset)\n",
    "print(metrics)\n",
    "# => {'accuracy': 0.8511806699615596}\n",
    "\n",
    "# Saving the trained model\n",
    "model.save_pretrained(\"setfit-bge-small-v1.5-sst2-8-shot\")\n",
    "# or\n",
    "model.push_to_hub(\"tomaarsen/setfit-bge-small-v1.5-sst2-8-shot\")\n",
    "\n",
    "# Loading a trained model\n",
    "model = SetFitModel.from_pretrained(\"tomaarsen/setfit-bge-small-v1.5-sst2-8-shot\") # Load from the Hugging Face Hub\n",
    "# or\n",
    "model = SetFitModel.from_pretrained(\"setfit-bge-small-v1.5-sst2-8-shot\") # Load from a local directory\n",
    "\n",
    "# Performing inference\n",
    "preds = model.predict([\n",
    "    \"It's a charming and often affecting journey.\",\n",
    "    \"It's slow -- very, very slow.\",\n",
    "    \"A sometimes tedious film.\",\n",
    "])\n",
    "print(preds)\n",
    "# => [\"positive\", \"negative\", \"negative\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import setfit, datasets\n",
    "from setfit import SetFitModel, Trainer, TrainingArguments\n",
    "\n",
    "\n",
    "class IntentClassifier:\n",
    "\n",
    "    def __init__(self, model_name=\"sentence-transformers/paraphrase-mpnet-base-v2\"):\n",
    "        \"\"\"Initialises the setfit model that will be used for the intent recognition\"\"\"\n",
    "\n",
    "        self.model = SetFitModel.from_pretrained(model_name)\n",
    "    \n",
    "    def train(self, labelled_utterances: List[Tuple[str,str]]):\n",
    "        \"\"\"Trains the setfit model on the labelled utterances\"\"\"\n",
    "\n",
    "        # Creates the dataset from the list of labelled utterances\n",
    "        train_data = datasets.Dataset.from_list([{\"text\":utt, \"label\":label} \n",
    "                                                 for utt,label in labelled_utterances])\n",
    "        \n",
    "        # Preparing the training arguments\n",
    "        args = TrainingArguments(\n",
    "            batch_size=32,\n",
    "            num_epochs=10,\n",
    "        )\n",
    "\n",
    "        # Preparing the trainer\n",
    "        self.trainer = Trainer(\n",
    "            model=self.model,\n",
    "            args=args,\n",
    "            train_dataset=train_data,\n",
    "        )\n",
    "\n",
    "        self.trainer.train()\n",
    "    \n",
    "    def get_intent_distrib(self, utterance:str):\n",
    "        \"\"\"Applies the trained model on a new utterance. The method should return a\n",
    "        dictionary that maps each possible intent category to a probability.\"\"\"\n",
    "\n",
    "        return self.model.predict(utterance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "model_head.pkl not found on HuggingFace Hub, initialising classification head with random weights. You should TRAIN this model on a downstream task to use it for predictions and inference.\n",
      "/Users/khoimai/Documents/uio/in4080/oblig_in4080_h2024/.venv/lib/python3.12/site-packages/datasets/utils/_dill.py:385: DeprecationWarning: co_lnotab is deprecated, use co_lines instead.\n",
      "  obj.co_lnotab,  # for < python 3.10 [not counted in args]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cf51116dd1b4bc28e4442f0ae55d8d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/95 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num unique pairs = 6426\n",
      "  Batch size = 32\n",
      "  Num epochs = 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4d57d5fcb5e4e3ba579ec5091b72d69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2010 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.2161, 'grad_norm': 1.2255741357803345, 'learning_rate': 9.950248756218906e-08, 'epoch': 0.0}\n",
      "{'embedding_loss': 0.1653, 'grad_norm': 0.7603353261947632, 'learning_rate': 4.975124378109453e-06, 'epoch': 0.25}\n",
      "{'embedding_loss': 0.0797, 'grad_norm': 0.3816811144351959, 'learning_rate': 9.950248756218906e-06, 'epoch': 0.5}\n",
      "{'embedding_loss': 0.0214, 'grad_norm': 0.5044553875923157, 'learning_rate': 1.492537313432836e-05, 'epoch': 0.75}\n",
      "{'embedding_loss': 0.0068, 'grad_norm': 0.05587809905409813, 'learning_rate': 1.990049751243781e-05, 'epoch': 1.0}\n",
      "{'embedding_loss': 0.0014, 'grad_norm': 0.01935669593513012, 'learning_rate': 1.945826423438364e-05, 'epoch': 1.24}\n",
      "{'embedding_loss': 0.0011, 'grad_norm': 0.01583503745496273, 'learning_rate': 1.890547263681592e-05, 'epoch': 1.49}\n",
      "{'embedding_loss': 0.0008, 'grad_norm': 0.017264029011130333, 'learning_rate': 1.8352681039248206e-05, 'epoch': 1.74}\n",
      "{'embedding_loss': 0.0007, 'grad_norm': 0.02904786542057991, 'learning_rate': 1.7799889441680487e-05, 'epoch': 1.99}\n",
      "{'embedding_loss': 0.0006, 'grad_norm': 0.005706049967557192, 'learning_rate': 1.724709784411277e-05, 'epoch': 2.24}\n",
      "{'embedding_loss': 0.0005, 'grad_norm': 0.007056326139718294, 'learning_rate': 1.6694306246545053e-05, 'epoch': 2.49}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63df6a3763984139ab89ed3162b9f339",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing widget examples:   0%|          | 0/1 [00:00<?, ?example/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'embedding_loss': 0.0005, 'grad_norm': 0.01723465695977211, 'learning_rate': 1.6141514648977338e-05, 'epoch': 2.74}\n",
      "{'embedding_loss': 0.0004, 'grad_norm': 0.009143025614321232, 'learning_rate': 1.558872305140962e-05, 'epoch': 2.99}\n",
      "{'embedding_loss': 0.0004, 'grad_norm': 0.011755071580410004, 'learning_rate': 1.5035931453841902e-05, 'epoch': 3.23}\n",
      "{'embedding_loss': 0.0004, 'grad_norm': 0.011029200628399849, 'learning_rate': 1.4483139856274187e-05, 'epoch': 3.48}\n",
      "{'embedding_loss': 0.0004, 'grad_norm': 0.008563637733459473, 'learning_rate': 1.393034825870647e-05, 'epoch': 3.73}\n",
      "{'embedding_loss': 0.0003, 'grad_norm': 0.005688668694347143, 'learning_rate': 1.3377556661138751e-05, 'epoch': 3.98}\n",
      "{'embedding_loss': 0.0004, 'grad_norm': 0.006756037939339876, 'learning_rate': 1.2824765063571034e-05, 'epoch': 4.23}\n",
      "{'embedding_loss': 0.0003, 'grad_norm': 0.006537584587931633, 'learning_rate': 1.2271973466003317e-05, 'epoch': 4.48}\n",
      "{'embedding_loss': 0.0003, 'grad_norm': 0.009121019393205643, 'learning_rate': 1.17191818684356e-05, 'epoch': 4.73}\n",
      "{'embedding_loss': 0.0003, 'grad_norm': 0.005917425267398357, 'learning_rate': 1.1166390270867884e-05, 'epoch': 4.98}\n",
      "{'embedding_loss': 0.0003, 'grad_norm': 0.007361388299614191, 'learning_rate': 1.0613598673300167e-05, 'epoch': 5.22}\n",
      "{'embedding_loss': 0.0003, 'grad_norm': 0.0067048994824290276, 'learning_rate': 1.0060807075732451e-05, 'epoch': 5.47}\n",
      "{'embedding_loss': 0.0003, 'grad_norm': 0.00577611243352294, 'learning_rate': 9.508015478164733e-06, 'epoch': 5.72}\n",
      "{'embedding_loss': 0.0003, 'grad_norm': 0.006838061846792698, 'learning_rate': 8.955223880597016e-06, 'epoch': 5.97}\n",
      "{'embedding_loss': 0.0003, 'grad_norm': 0.005673190578818321, 'learning_rate': 8.402432283029299e-06, 'epoch': 6.22}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.006467117462307215, 'learning_rate': 7.849640685461582e-06, 'epoch': 6.47}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.005967443808913231, 'learning_rate': 7.296849087893865e-06, 'epoch': 6.72}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.009445813484489918, 'learning_rate': 6.744057490326148e-06, 'epoch': 6.97}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.007624962832778692, 'learning_rate': 6.19126589275843e-06, 'epoch': 7.21}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.0067652566358447075, 'learning_rate': 5.638474295190714e-06, 'epoch': 7.46}\n",
      "{'embedding_loss': 0.0003, 'grad_norm': 0.005564119666814804, 'learning_rate': 5.085682697622997e-06, 'epoch': 7.71}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.0036761632654815912, 'learning_rate': 4.53289110005528e-06, 'epoch': 7.96}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.007268563844263554, 'learning_rate': 3.980099502487563e-06, 'epoch': 8.21}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.005203272681683302, 'learning_rate': 3.4273079049198452e-06, 'epoch': 8.46}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.006464516744017601, 'learning_rate': 2.8745163073521287e-06, 'epoch': 8.71}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.00608673132956028, 'learning_rate': 2.3217247097844113e-06, 'epoch': 8.96}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.007610644679516554, 'learning_rate': 1.7689331122166945e-06, 'epoch': 9.2}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.008527561090886593, 'learning_rate': 1.2161415146489775e-06, 'epoch': 9.45}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.0063884020783007145, 'learning_rate': 6.633499170812604e-07, 'epoch': 9.7}\n",
      "{'embedding_loss': 0.0002, 'grad_norm': 0.006027992814779282, 'learning_rate': 1.105583195135434e-07, 'epoch': 9.95}\n",
      "{'train_runtime': 679.9829, 'train_samples_per_second': 94.502, 'train_steps_per_second': 2.956, 'train_loss': 0.007155870156367286, 'epoch': 10.0}\n"
     ]
    }
   ],
   "source": [
    "classifier = IntentClassifier()\n",
    "classifier.train(labelled_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we don't have any test data, we cannot really conduct an evaluation of the classification performance, but this step would be of course strongly adviced when developing a real system. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slot filling\n",
    "\n",
    "In addition to the intents themselves, we also wish to detect some slots, such as floor numbers or person names. For this step, we will not use a data-driven model, but rather rely on an old-fashioned, rule-based approach:\n",
    "- For floor numbers, we will rely on string matching (with regular expressions or basic string search) that detect patterns such as \"X floor\" (where X is [first,second, third, fourth, fifth, sixth, seventh, eighth, ninth, tenth]) or \"floor X\" (where X is between 1 and 10).\n",
    "- For person names, we have a predefined list of person names to detect (employees at IFI), and we should simply search for their occurrence in the user input. The simplest implementation is to just for look for exact occurrences. However, since speech recognition will often struggle to recognize foreign person names, an even better approach would be to search for names that are phonetically close (you can use the `jellyfish` library for this).\n",
    "\n",
    "The results of the slot filling should be a dictionary mapping slot names to a canonical form of the slot value. For instance, if the utterance contains the expression \"ninth floor\", the resulting slot dictionary should be `{\"floor_number\":9}`. Similarly, the `employee_name` slot should be a name present in `OFFICES` dictionary. \n",
    "\n",
    "__Task 1.4__ (2 points): Implement the method `fill_slots` that will detect the occurrence of those slots in the user input.<br>\n",
    "(+ 1 bonus point if you implement a fuzzy matching strategy to find person names that are phonetically close)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Floor numbers for a subset of the IFI employees\n",
    "OFFICES = {'Adín Ramírez Rivera': 4, 'Andreas Austeng': 4, 'Anne H Schistad Solberg': 4, \n",
    "           'Arild Torolv Søetorp Waaler': 9, 'Audun Jøsang': 9, 'Birthe Soppe': 4, 'Carsten Griwodz': 4,\n",
    "           'Dag Sjøberg': 9, 'Dag Trygve Eckhoff Wisland': 5, 'Einar Broch Johnsen': 8, \n",
    "           'Eric Bartley Jul': 10, 'Erik Velldal': 4, 'Henrik Skaug Sætra': 7, 'Ingrid Chieh Yu': 8,\n",
    "           'Jørn Anders Braa': 6, 'Kristin Bråthen': 4, 'Kyrre Glette': 4, 'Lars Groth': 6, \n",
    "           'Lilja Øvrelid': 4, 'Maja Van Der Velden': 7, 'Martin Giese': 9, 'Michael Welzl': 5, \n",
    "           'Miria Grisot': 6, 'Nils Gruschka': 9, 'Olaf Owe': 9, 'Ole Christian Lingjærde': 4, \n",
    "           'Ole Hanseth': 6, 'Paulo Ferreira': 10, 'Philipp Dominik Häfliger': 5, 'Philipp Häfliger': 5, \n",
    "           'Roman Vitenberg': 4, 'Silvia Lizeth Tapia Tarifa': 8, 'Stephan Oepen': 4, \n",
    "           'Sundeep Sahay': 6, 'Thomas Peter Plagemann': 4, 'Tone Bratteteig': 7, 'Torbjørn Rognes': 8, \n",
    "           'Truls Erikson': 6, 'Viktoria Stray': 10, 'Yngvar Berg': 5, 'Yves Scherrer': 4, \n",
    "           'Özgü Mira Alay-Erduran': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/khoimai/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import jellyfish\n",
    "from typing import Dict, Union\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# Download stopwords if not already downloaded\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def fuzzy_matching_name(user_input: str) -> str:\n",
    "    \"\"\"\n",
    "    Fuzzy matches the user input to the closest employee name in the OFFICES dictionary.\n",
    "    Returns the best match if the similarity score is above 0.75, otherwise returns None.\n",
    "    \"\"\"\n",
    "    best_match, highest_score = None, 0\n",
    "\n",
    "    # Remove stopwords from user input\n",
    "    input_parts = [word for word in user_input.split() if word.lower() not in stop_words]\n",
    "    possible_name_string = \" \".join(input_parts)\n",
    "\n",
    "    # Extract potential names from the cleaned input\n",
    "    possible_names = re.findall(r'[A-Z][a-z]*\\s*[A-Z]*[a-z]*', possible_name_string)\n",
    "\n",
    "    # Calculate similarity for each possible name component\n",
    "    for possible_name in possible_names:\n",
    "        for name in OFFICES.keys():\n",
    "            match_score = jellyfish.jaro_winkler_similarity(possible_name, name)\n",
    "            # Update the best match if score is higher\n",
    "            if match_score > highest_score:\n",
    "                best_match, highest_score = name, match_score\n",
    "\n",
    "    return best_match if highest_score > 0.7 else None\n",
    "\n",
    "def fill_slots(user_input: str) -> Dict[str, Union[int, str]]:\n",
    "    \"\"\"Extracts the set of slots detected in the user inputs. More precisely, the method\n",
    "    should detect both floor numbers and person names, and return a dictionary mapping slot \n",
    "    names (in this case either `floor_number` or `employee_name`) to its corresponding\n",
    "    value, in canonical form (integer for the floor number, string for the employee name)\"\"\"\n",
    "\n",
    "    slots = {}\n",
    "\n",
    "    # Mapping words to floor numbers\n",
    "    floor_word_to_number = {\n",
    "        \"first\": 1, \"second\": 2, \"third\": 3, \"fourth\": 4, \"fifth\": 5,\n",
    "        \"sixth\": 6, \"seventh\": 7, \"eighth\": 8, \"ninth\": 9, \"tenth\": 10\n",
    "    }\n",
    "\n",
    "    # Regular expressions to detect \"floor X\" or \"X floor\" patterns\n",
    "    floor_pattern = re.compile(r\"\\b(floor\\s+(\\d+)|(\\d+)\\s+floor|({}))\\b\".format(\n",
    "        \"|\".join(floor_word_to_number.keys())), re.IGNORECASE)\n",
    "\n",
    "    # Search for floor patterns in the input\n",
    "    floor_match = floor_pattern.search(user_input)\n",
    "    if floor_match:\n",
    "        if floor_match.group(2):  # Matches \"floor X\"\n",
    "            slots[\"floor_number\"] = int(floor_match.group(2))\n",
    "        elif floor_match.group(3):  # Matches \"X floor\"\n",
    "            slots[\"floor_number\"] = int(floor_match.group(3))\n",
    "        elif floor_match.group(4):  # Matches words like \"first\", \"second\", etc.\n",
    "            slots[\"floor_number\"] = floor_word_to_number[floor_match.group(4).lower()]\n",
    "\n",
    "    # Search for exact matches of employee names\n",
    "    exact_matches = [name for name in OFFICES.keys() if name.lower() in user_input.lower()]\n",
    "    if exact_matches:\n",
    "        slots[\"employee_name\"] = exact_matches[0]\n",
    "    else:\n",
    "        fuzzy_match = fuzzy_matching_name(user_input)\n",
    "        if fuzzy_match:\n",
    "            slots[\"employee_name\"] = fuzzy_match\n",
    "\n",
    "    return slots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'floor_number': 9}\n",
      "{'employee_name': 'Andreas Austeng'}\n",
      "{'floor_number': 3}\n",
      "{'employee_name': 'Olaf Owe'}\n",
      "{'employee_name': 'Andreas Austeng'}\n",
      "{'floor_number': 9}\n",
      "{'floor_number': 9}\n",
      "{'employee_name': 'Olaf Owe'}\n",
      "{'employee_name': 'Andreas Austeng'}\n"
     ]
    }
   ],
   "source": [
    "# Test cases for the fill_slots function\n",
    "\n",
    "print(fill_slots(\"Could you take me to the ninth floor?\"))  \n",
    "print(fill_slots(\"I would like to visit Andreas Austeng\"))  \n",
    "print(fill_slots(\"Take me to floor 3\"))  \n",
    "print(fill_slots(\"Where is Olaf Owe located?\")) \n",
    "print(fill_slots(\"Could you tell me where Andreas Austeng's office is?\"))  \n",
    "print(fill_slots(\"Take me to floor 9\"))\n",
    "print(fill_slots(\"Take me to floor ninth\"))  \n",
    "print(fill_slots(\"Where is Olaf Owe?\"))\n",
    "print(fill_slots(\"I'd like to see Andreas Austen\"))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'employee_name': 'Andreas Austeng'}\n",
      "{'employee_name': 'Andreas Austeng'}\n",
      "{'employee_name': 'Olaf Owe'}\n",
      "{'employee_name': 'Olaf Owe'}\n",
      "{'employee_name': 'Olaf Owe'}\n",
      "{'employee_name': 'Philipp Häfliger'}\n",
      "{'employee_name': 'Philipp Häfliger'}\n",
      "{'employee_name': 'Philipp Häfliger'}\n",
      "{'employee_name': 'Eric Bartley Jul'}\n",
      "{'employee_name': 'Eric Bartley Jul'}\n",
      "{'employee_name': 'Eric Bartley Jul'}\n"
     ]
    }
   ],
   "source": [
    "# Test case for fuzzy matching\n",
    "\n",
    "# 'Andreas Austeng'\n",
    "print(fill_slots(\"I'd like to visit Andreas Austen\"))\n",
    "print(fill_slots(\"I want to speak with Andres Austeng\"))\n",
    "\n",
    "# 'Olaf Owe'\n",
    "print(fill_slots(\"Where is Olaf Oh's office located?\"))\n",
    "print(fill_slots(\"Please tell me about Olaf Owa\"))\n",
    "print(fill_slots(\"Could you find Olaf Aw's office?\"))\n",
    "\n",
    "# 'Philipp Häfliger'\n",
    "print(fill_slots(\"Where can I find Phillip Hafliger?\"))\n",
    "print(fill_slots(\"I need to talk to Philip Heffliger\"))\n",
    "print(fill_slots(\"Could you direct me to Phillip Hefligar?\"))\n",
    "\n",
    "# 'Eric Bartley Jul'\n",
    "print(fill_slots(\"Is Erik Bartly in his office?\"))\n",
    "print(fill_slots(\"Can you show me where Eric Jul's office is?\"))\n",
    "print(fill_slots(\"Please guide me to Eric Bartley Jewel\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Response selection\n",
    "\n",
    "The next step is to implement the response selection mechanism. The response will depend on various factors:\n",
    "- the inferred user intents from the user utterance\n",
    "- the detected slot values in the user utterance (if any)\n",
    "- the current floor\n",
    "- the list of next floor stops that are yet to be reached\n",
    "- the dialogue history (as a list of dialogue turns).\n",
    "\n",
    "The response may consist of verbal responses (enacted by calls to `_say_to_user`) but also physical actions, represented by calls to either `move_to_floor` or `stop`. \n",
    "\n",
    "__Task 1.5__ (3 points): Implement the method `_respond`, which is responsible for selecting and executing those responses. The responses should satisfy the aforementioned conversational criteria (provide grounding feedback, use confirmations and clarification requests etc.). This method will consist in practice of many _if...then...else_ blocks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def _respond(self, intent_distrib: Dict[str, float], slots: Dict[str,str]) :\n",
    "#     \"\"\"Given a probability distribution over possible intents, an a (possibly empty) list\n",
    "#     of detected slots in the user input, decide how to react. The method should lead\n",
    "#     to calls to both physical actions (move_to_floor, stop) and dialogue responses \n",
    "#     (via _say_to_user).\"\"\"\n",
    "\n",
    "#     raise NotImplementedError(\"\")\n",
    "\n",
    "# setattr(TalkingElevator, \"_respond\", _respond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TalkingElevator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[94], line 70\u001b[0m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_say_to_user(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSorry, I don\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt understand you, pal\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 70\u001b[0m \u001b[38;5;28msetattr\u001b[39m(\u001b[43mTalkingElevator\u001b[49m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_respond\u001b[39m\u001b[38;5;124m\"\u001b[39m, _respond)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TalkingElevator' is not defined"
     ]
    }
   ],
   "source": [
    "def _respond(self, intent_distrib: Dict[str, float], slots: Dict[str, Union[int, str]]):\n",
    "    \"\"\"Given a probability distribution over possible intents, and a (possibly empty) list\n",
    "    of detected slots in the user input, decide how to react. The method should lead\n",
    "    to calls to both physical actions (move_to_floor, stop) and dialogue responses \n",
    "    (via _say_to_user).\"\"\"\n",
    "\n",
    "    # Determine the most likely intent\n",
    "    intent = max(intent_distrib, key=intent_distrib.get)\n",
    "    confidence = intent_distrib[intent]\n",
    "\n",
    "    # Handle different intents\n",
    "    if intent == \"RequestMoveToFloor\":\n",
    "        if \"floor_number\" in slots:\n",
    "            floor_number = slots[\"floor_number\"]\n",
    "            if 1 <= floor_number <= 10:\n",
    "                self._say_to_user(f\"Ok, going to the {floor_number}th floor.\")\n",
    "                self.move_to_floor(floor_number)\n",
    "            else:\n",
    "                self._say_to_user(\"Sorry, the floor number must be between 1 and 10.\")\n",
    "        else:\n",
    "            self._say_to_user(\"Which floor would you like to go to?\")\n",
    "\n",
    "    elif intent == \"RequestMoveRelative\":\n",
    "        if \"floor_number\" in slots:\n",
    "            relative_floor = slots[\"floor_number\"]\n",
    "            target_floor = self.cur_floor + relative_floor\n",
    "            if 1 <= target_floor <= 10:\n",
    "                self._say_to_user(f\"Ok, moving {relative_floor} floors.\")\n",
    "                self.move_to_floor(target_floor)\n",
    "            else:\n",
    "                self._say_to_user(\"Sorry, that would take us out of the building's range.\")\n",
    "        else:\n",
    "            self._say_to_user(\"How many floors would you like to move?\")\n",
    "\n",
    "    elif intent == \"RequestOfficeLocation\":\n",
    "        if \"employee_name\" in slots:\n",
    "            employee_name = slots[\"employee_name\"]\n",
    "            if employee_name in OFFICES:\n",
    "                office_floor = OFFICES[employee_name]\n",
    "                self._say_to_user(f\"The office of {employee_name} is on the {office_floor}th floor. Do you wish to go there?\")\n",
    "            else:\n",
    "                self._say_to_user(f\"Sorry, I don't know where {employee_name}'s office is.\")\n",
    "        else:\n",
    "            self._say_to_user(\"Whose office are you looking for?\")\n",
    "\n",
    "    elif intent == \"RequestCurrentFloor\":\n",
    "        self._say_to_user(f\"We are currently on the {self.cur_floor}th floor.\")\n",
    "\n",
    "    elif intent == \"Confirm\":\n",
    "        if self.next_stops:\n",
    "            next_floor = self.next_stops[0]\n",
    "            self._say_to_user(f\"Ok, continuing to the {next_floor}th floor.\")\n",
    "        else:\n",
    "            self._say_to_user(\"There is no pending floor request to confirm.\")\n",
    "\n",
    "    elif intent == \"Stop\":\n",
    "        self.stop()\n",
    "        self._say_to_user(\"The elevator has been stopped. Where would you like to go?\")\n",
    "\n",
    "    elif intent == \"Repeat\":\n",
    "        if self.dialogue_history:\n",
    "            last_system_turn = next(turn for turn in reversed(self.dialogue_history) if turn[\"speaker\"] == \"elevator\")\n",
    "            self._say_to_user(f\"I said: {last_system_turn['text']}\")\n",
    "        else:\n",
    "            self._say_to_user(\"I haven't said anything yet.\")\n",
    "\n",
    "    else:\n",
    "        self._say_to_user(\"Sorry, I don't understand you, pal\")\n",
    "\n",
    "setattr(TalkingElevator, \"_respond\", _respond)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "The last step is to implement the `process_input` method in the `TalkingElevator` class. The method should rely on the intent recognition, slot filling and response selection mechanism (which you have implemented in the previous steps) to react to a given user input.\n",
    "\n",
    "**Task 1.6** (1 point): Implement the `process_input` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    \n",
    "\n",
    "def process_input(self, user_input: str, conf_score:float=1.0):\n",
    "    \"\"\"Processes the (transcribed) user input, and respond appropriately \n",
    "    (through a verbal response and possibly also an action, such as moving floors).\n",
    "    The method should rely on the intent classifier, slot-filling function, and\n",
    "    response selection function.\"\"\"\n",
    "\n",
    "    self._add_to_dialogue_history(user_input, speaker=\"user\", conf_score=conf_score)\n",
    "    raise NotImplementedError()\n",
    "\n",
    "setattr(TalkingElevator, \"process_input\", process_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to test our talking elevator: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "elevator = TalkingElevator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your talking elevator will mostly likely not function properly right from the start. Identify what works and what doesn't and correct the code you have developed in Tasks 1.1 - 1.6 until your system meets the specifications we have outlined. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 : Machine translation\n",
    "\n",
    "In this part, we evaluate a pre-trained machine translation model on data from the Lord of the Rings movies and fine-tune it to improve the translation quality.\n",
    "\n",
    "### Data\n",
    "\n",
    "We provide you with two files, `lotr.detok.de` and `lotr.detok.en`, containing German and English movie subtitles. These two files constitute a so-called _parallel corpus_, i.e. each sentence/line in German corresponds to a sentence/line in English. The two files have the same number of lines and the German sentence on line $i$ corresponds to the English sentence on line $i$. The subtitles are extracted from the [OpenSubtitles-2018](https://opus.nlpl.eu/OpenSubtitles/corpus/version/OpenSubtitles) corpus.\n",
    "\n",
    "Here are the first ten lines of the two files:\n",
    "\n",
    "<style scoped>\n",
    "table {\n",
    "  font-size: 12px;\n",
    "}\n",
    "</style>\n",
    "| Nb  | German (`lotr.detok.de`)         | English (`lotr.detok.en`)      |\n",
    "|---|----------------------------------|--------------------------------|\n",
    "| 1 | Die Welt ist im Wandel. | The world is changed.   |\n",
    "| 2 | Ich spüre es im Wasser. | I feel it in the water. |\n",
    "| 3 | Ich spüre es in der Erde. | I feel it in the earth. |\n",
    "| 4 | Ich rieche es in der Luft. | I smell it in the air. |\n",
    "| 5 | Vieles, was einst war, ist verloren, da niemand mehr lebt, der sich erinnert. | Much that once was is lost. For none now live who remember it. |\n",
    "| 6 | Es begann mit dem Schmieden der Großen Ringe. | It began with the forging of the Great Rings. |\n",
    "| 7 | 3 wurden den Elben gegeben, den unsterblichen, weisesten und reinsten aller Wesen. | Three were given to the Elves: Immortal, wisest and fairest of all beings. |\n",
    "| 8 | 7 den Zwergenherrschern, großen Bergleuten und Handwerkern in ihren Hallen aus Stein. | Seven to the Dwarf-lords: Great miners and craftsmen of the mountain halls. |\n",
    "| 9 | Und 9... 9 Ringe wurden den Menschen geschenkt, die vor allem anderen nach Macht streben. | And nine nine rings were gifted to the race of Men who, above all else, desire power. |\n",
    "| 10 | Denn diese Ringe bargen die Kraft und den Willen, jedes Volk zu leiten. | For within these rings was bound the strength and will to govern each race. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting started\n",
    "\n",
    "We will a pretrained machine translation model for German-to-English translation. The model is available on the HuggingFace model hub and can be used with the `transformers` library.\n",
    "\n",
    "Let us first make sure that all required modules are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install torch transformers accelerate evaluate sacrebleu sacremoses sentencepiece unbabel-comet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bilingual model is called [`opus-mt-de-en`](https://huggingface.co/Helsinki-NLP/opus-mt-de-en) and has been trained by the Helsinki-NLP group. Like (almost) all HuggingFace models, it consists of a _tokenizer_ and the _sequence-to-sequence model_ properly speaking. We need to load both separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "\n",
    "tokenizer = transformers.AutoTokenizer.from_pretrained(\"helsinki-nlp/opus-mt-de-en\")\n",
    "translator = transformers.AutoModelForSeq2SeqLM.from_pretrained(\"helsinki-nlp/opus-mt-de-en\")\n",
    "\n",
    "# Change \"cuda\" to \"cpu\" if you're running on a machine without GPU\n",
    "device = \"cuda\"\n",
    "translator = translator.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `transformers` library will automatically download the models from the HuggingFace hub the first time you run this cell, so it may take a bit longer.\n",
    "\n",
    "Let's take the first two German sentences, tokenize them, and translate them to English:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer([\"Die Welt ist im Wandel.\", \"Ich spüre es im Wasser.\"], return_tensors=\"pt\", padding=True)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = translator.generate(**tokens.to(device), max_new_tokens=50)\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.1__ (1 point):\n",
    "- What do the numbers in the `input_ids` represent?\n",
    "- What is the effect of `padding=True`? How would the data look like if padding was disabled?\n",
    "- What does `max_new_tokens` do? Why do you think it is important to set this parameter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get actual words by running the output through the `batch_decode` function of the tokenizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(translations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ We assume that you will run the translations from German to English. If you would like to work on the opposite translation direction (and feel comfortable evaluating the German output), you are welcome to do so. The corresponding bilingual model is called `opus-mt-en-de`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data splitting\n",
    "\n",
    "Before we move on, we need to split our data. We will evaluate different models and for that we'll need test data. We will also fine-tune a model, and for that we'll need training data. The entire Lord of the Rings dataset has 9640 lines.\n",
    "\n",
    "__Task 2.2__ (1 point): Split the dataset in such a way that the **last** 1000 lines are used for testing and the remaining lines (8640) for training. Save the data under the following filenames: `lotr.train.de, lotr.train.en, lotr.test.de, lotr.test.en`. You can use Python code or other tools to perform the splitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.3__ (1 point): What are potential risks and drawbacks of splitting the dataset in this way? \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to translate the test set with our model.\n",
    "\n",
    "__Task 2.4__ (2 points): Create a function that loads the entire `lotr.test.de` file, translates each line with the `opus-mt-de-en` model and writes its output to a new file, one sentence per line.\n",
    "\n",
    "The easiest way to do this is to just load the entire test file into a list, tokenize and translate it, but the test set may be too large to fit on GPU memory, or it might be inefficient and slow if you use a CPU. A better alternative is to split the data into batches of 50-100 sentences and send each batch separately to the translator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate(input_file, translation_file, tokenizer, translator, batch_size=100):\n",
    "    \"\"\"Translate an input file line by line using the loaded tokenizer and translator,\n",
    "    and write the translations to output_file.\"\"\"\n",
    "    pass\n",
    "\n",
    "\n",
    "translate(\"lotr.test.de\", \"lotr.output_opus.en\", tokenizer, translator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before moving on, open the output file and check that the translations look ok. In particular, the file should contain the expected number of lines and output should be in the expected language (English or German, depending on the chosen direction).\n",
    "\n",
    "__Task 2.5__ (1 point): Open both the output file and the reference translations (`lotr.test.en` if translating from German to English) and compare the first 20 lines. How would you rate the translations of the OPUS system on a scale from 1 (incomprehensible and/or completely different meaning) to 5 (grammatically correct and meaning fully preserved)? Justify your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "We can now evaluate the quality of our translations. In a first step, we perform _reference-based surface-level evaluation_  using the popular BLEU score. We can do that with the `sacrebleu` module. Below is a slightly reformatted example taken from the [SacreBLEU documentation](https://github.com/mjpost/sacrebleu/tree/master?tab=readme-ov-file#using-sacrebleu-from-python):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU\n",
    "\n",
    "reference = ['The dog bit the man.', 'It was not unexpected.', 'The man bit him first.']\n",
    "hypothesis = ['The dog bit the man.', \"It wasn't surprising.\", 'The man had just bitten him.']\n",
    "\n",
    "bleu_scorer = BLEU()\n",
    "# BLEU can deal with multiple references per sentence, but here we only have one, so we just enclose it in another set of brackets:\n",
    "score = bleu_scorer.corpus_score(hypothesis, [reference])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.6__ (1 point): Load both the system output and the reference of your test set and compute the corpus-level BLEU score. Also compute the corpus-level chrF score. Which of the scores is higher?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sacrebleu.metrics import BLEU, CHRF\n",
    "\n",
    "def evaluate_bleu(hypothesis_file, reference_file):\n",
    "\tpass\n",
    "\n",
    "evaluate_bleu(\"lotr.output_opus.en\", \"lotr.test.en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Besides string-based metrics, neural metrics have become increasingly popular lately, since they have been shown to correlate better with human judgements. The most popular neural metric is called COMET and it can be used with the HuggingFace `evaluate` package. The example below is from the [documentation](https://huggingface.co/spaces/evaluate-metric/comet/blob/main/README.md):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "comet_metric = evaluate.load('comet')\n",
    "src = [\"Dem Feuer konnte Einhalt geboten werden\", \"Schulen und Kindergärten wurden eröffnet.\"]\n",
    "hyp = [\"The fire could be stopped\", \"Schools and kindergartens were open\"]\n",
    "ref = [\"They were able to control the fire.\", \"Schools and kindergartens opened\"]\n",
    "comet_score = comet_metric.compute(predictions=hyp, references=ref, sources=src)\n",
    "print(comet_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Task 2.7__ (1 point): Adapt this code to evaluate the output of the OPUS model. Note that COMET also requires the source text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_comet(hypothesis_file, reference_file, source_file):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "\n",
    "Let us see now if we can further improve the translation quality. We still haven't used the training set after all...\n",
    "\n",
    "Fine-tuning a translation model with the `transformers` library is a bit convoluted. You need the following ingredients:\n",
    "- A `Seq2SeqTrainer` object, which defines the initial model and its tokenizer, the training data, and the configuration parameters (as a `Seq2SeqTrainingArguments` object). The training process starts with the `train()` method.\n",
    "- A `Seq2SeqTrainingArguments` object, which contains the configuration parameters, such as the number of training epochs, the path for saving the fine-tuned model, the learning rate etc.\n",
    "- A `DataCollatorForSeq2Seq` object that takes care of splitting the training data into batches of appropriate size.\n",
    "- A `DatasetDict` object containing the tokenized training data. Typically, the untokenized data is loaded into a `DatasetDict` object, and the tokenization function is applied to everything inside this `DatasetDict` using the `map()` function.\n",
    "\n",
    "__Task 2.8__ (1 point): The code in the box below shows a working example using the pretrained OPUS model, but is limited to two sentence pairs. Complete the code to load the entire training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "max_length = 100\n",
    "\n",
    "ds = Dataset.from_dict({\n",
    "    \"src_text\": [\"Die Welt ist im Wandel.\", \"Ich spüre es im Wasser.\"],\n",
    "    \"tgt_text\": [\"The world is changed.\", \"I feel it in the water.\"]\n",
    "})\n",
    "data = DatasetDict({\"train\": ds})\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(examples[\"src_text\"], text_target=examples[\"tgt_text\"], max_length=max_length, truncation=True)\n",
    "    return model_inputs\n",
    "\n",
    "tokenized_datasets = data.map(preprocess_function, batched=True)\n",
    "print(tokenized_datasets)\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=translator)\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"opus-mt-de-en-lotr\",\n",
    "    evaluation_strategy=\"no\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=32,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=3,\n",
    "    predict_with_generate=True\n",
    ")\n",
    "\n",
    "trainer = Seq2SeqTrainer(\n",
    "    translator,\n",
    "    args,\n",
    "    train_dataset=tokenized_datasets[\"train\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model was fine-tuned for three epochs, and you should have three checkpoints in the `opus-mt-de-en-lotr` directory.\n",
    "\n",
    "__Task 2.9__ (1 point): Choose one of the checkpoints and use it to translate the test set. Evaluate the test set with BLEU, chrF and COMET. Note that locally saved model files (and tokenizers) can be loaded in the same way as models from the HuggingFace hub, e.g. with the following command: `transformers.AutoModelForSeq2SeqLM.from_pretrained(\"opus-mt-de-en-lotr/checkpoint-810\")`\n",
    "\n",
    "Did fine-tuning help? Did fine-tuning help? Have a look at the first rows of the files. Do you agree with the metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
